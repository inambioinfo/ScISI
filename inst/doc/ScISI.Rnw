%
% NOTE -- ONLY EDIT ScISI.Rnw!!!
%
%\VignetteIndexEntry{ScISI Working Paper}
%\VignetteDepends{}
%\VignetteKeywords{Interactome}
%\VignettePackage{ScISI}
\documentclass{article}

\usepackage{hyperref}

\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textsf{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}



\newcommand{\classdef}[1]{%
  {\em #1}
}

\begin{document}
\title{Creating in Silico Interactomes}
\maketitle

\section{Introduction}

Protein complexes form a fundamental part of biology and are relevant
to our understanding of complex biological processes and to
deciphering the different roles played by genes and proteins.
A number of high throughput experiments have been carried out with the
goal of helping to better elucidate the nature and number of
interactions present \cite{Gavin, Ho, Krogan, Ito, Uetz}. We have
carried out a number of different investigations of these data
\cite{Scholtens, ScholtensVidalGent} which have focused on the
estimation of protein complex co-memberships. In our discussion we do
not distinguish between the term gene and the term protein, since the
available resolution is not fine enough and equating these concepts
leads to a more comprehensible dialog. The methodology is sufficiently
general to be able to address the more complex situation of different
protein/polypeptide variants should they arise.

In this paper we consider the problem of estimating an \textit{in
  silico} interactome for Saccharomyces cerevisiae. 
The role of the \textit{in silico} interactome
is to  provide a tool that can be used to carry out a variety of
computational experiments. These experiments will help to confirm the
viability of wet lab experimental procedures by allowing investigators
to alter experimental conditions (both stochastic and systematic
errors can be modified) and to measure how the outputs change as the
error rates do. Another purpose for the \textit{in silico} interactome
is to provide a tool that can generate multiple data sets, under
different conditions, so that the statistical properties of different
of proposed estimation procedures can be directly compared. A third
use for the \textit{in silico} interactome is to use it to help
develop tools and strategies for small scale experiments that will
probe the interactome at a very detailed level. For example, a
reasonable strategy to investigate a coherent set of protein complexes
is to first select a small number of candidates and explore their
interactions, say via affinity purification (co-precipitation)
experiments. Once the first experiment has been collected one would
like to analyze the data and determine an optimal, or nearly optimal
set of baits for future experiments. Finally, a fourth use of an
\textit{in silico} interactome is to study the effect of perturbations
in the network, such perturbations could be caused by evolution and
hence could become part of the study of evolutionary pressure on the
interactome, or they could be due to drug treatments and hence would
become part of a clinical investigation into the likely effects of
drug treatments.
%%FIXME: we could also mention studying the effects of sampling as yet
%%another use of the interactome.

Important design considerations include the fact that genomic science
is rapidly evolving and that new data sources will continuously come
on line. Hence there must be a mechanism by which the interactome can
be updated. There are many different and disparate data sources, there
should be some mechanism for incorporating all available
data. Different investigators will want to modify the interactome,
either with localy produced, but not yet public data, or to satisfy
personal beliefs. We have developed a paradigm that allows
investigators to create their own estimates, to share interactomes and
to build, revise and update interactomes.

We are aware of the very dynamic nature of protein interactions and
that different interactions occur at different times and under
different conditions. In this paper we consider the description of an
interactome, that can be thought of as representing the state of a
single type of cell (our example will be based on
\textit{S. cerevisiae} where there is a single cell, but where
different conditions could conceivably result in different
interactomes). We leave the problem of representing state-dependent
interactomes for a separate report.

In this paper we first describe the primary data sources used to
collect data for the interactome. We then describe how those data
sources are combined to provide a comprehensive interactome that can
be used as an input for the various computational tasks described above.

\section{Materials and Methods}

In this section we first describe what we mean by a protein complex
and describe different models for representing these data. We then
describe the process of creating an \textit{in silico} interactome
based on two public meta-data sources and three experimental data sets 
by combining purification of protein complexes with identification of 
their individual componenets via mass spectroscopy.


\subsection{Protein complexes and their representations}

%%FIXME: a few pictures would surely help readers
A protein complex (defined for this paper) is two or more
proteins that physically interact for the purposes of carrying out
some biological objective. There is no need for all members of a
complex to interact with each one another, but all the proteins do need
to combine to form a macro-proteomic structure. We further note that 
some proteins will be involved in many complexes
while others will be involved in relatively few, and one corollary 
to this remark is that the relative size of the protein complexes 
range from two proteins to more than fifty. 

This definition of a protein complex is motivated by the various 
technologies that assay levels of protein complex composition such 
as Affinity Purification - Mass Spectroscopy and 
Co-immunoprecipitation. Working within the confines of these 
technologies, our definition for protein complexes becomes 
increasingly strict. There are structures within the cytoskeleton,
for instance, which fit within a more generic setting of a complex; 
these structures are never pulled down by the mentioned 
technologies, so we have dis-allowed their membership as a protein
complex. 

What should be said about sub-complexes? When sub-complexes exist
there can be identifiability problems that arise due to the technology
being used. FIXME: it would be good to give some sort of concrete
example of what might go wrong. (Also, some protein complexes might
be a sub-complex given other conditions...where should we draw the 
line between when a complex is actually a sub-complex or not??? TC) 

We have chosen to represent the protein complex co-membership graph as
a bipartite graph, $B$. The proteins themselves index one set 
of nodes which we denote as $P$ while the protein complexes index
the other set of nodes which we denote as $C$. A protein specific
node $p_i$ is incident to a protein complex specific node $c_j$ if $p_i$ 
has membership in $c_j$. We remark that there is an equivalence between the categories
of bi-partite graphs and the categories of hyper-graphs (cite or supplementary).

To each bi-partite graph comes an associated incidence matrix representation. 
This incidence matrix representation, $M_B$, is a $\{0,1\}$-matrix where proteins
index the rows and protein complexes index the columns. The entries of $M_B$ 
correspond to the presence or absence of membership edges, for instance, the $(i,j)$ 
entry for $M_B$ is unity if protein $p_i$ is a constituent member of complex
$c_j$; the entry is zero otherwise. 

Because most computational methodologies desire this incidence matrix representation
rather than the actual bi-partite graph itself, the construction of the \textit{in silico}
interactome will be the construction of a particular incidence matrix.  

Having streamlined a definition for protein complex and its computational representation, 
we move forward with the task of diciphering an \textit{in silico} interactome for S. 
cerevisae. To this end, we have gathered information from  
two online data sources, Gene Ontology and the Munich Information Center for Protein 
Sequences, as well as high-level protein complex estimates from three publicly available 
wet-lab experiments. 


\subsection{MIPS}

The MIPS comprehensive yeast genome database is a functional catalogue that provides tools to browse genome wide information 
for a number of organisms including S. cerevisae. Within the complex section of the catalogue, the MIPS database has 
created a hierarchial system of documenting a more general version of a protein complex that what we have defined. For
instance, the MIPS database catalogues many of the structures of the cytoskeleton as complexes; these 
structures do not intersect with our definition of protein complexes. Though 
this hierarchy is more general, an overwhelming majority of the MIPS protein complexes do comply with our definition, and 
these complexes will play an important role in the \textit{in silico} interactome.

In addition to the MIPS definition of protein complex, MIPS also documents the protein complexes estimated by the wet-lab
experiments of (Gavin, Ho, Krogan). Whereas the other complexes documented within MIPS arise from small scale systematic
protein complex composition experiments, these wet-lab protein complex estimates come from high through-put wet-lab data 
sets which tend to contain higher levels of error. The data sets rendered by the wet-lab experiments do not give any 
indication of complex composition, but rather a lower level of co-membership between bait proteins and prey proteins. Each 
experiment has independently devised a clustering algorithm to estimate protein complex composition. This brings a level of
inconsistancy to protein complex estimation. We have developed a singular process to remove this inconsistancy (the
details of which will be given in the following sections) and so we have chosen not to use the MIPS estimates of the
high through-put data.

The main task in building the \textit{in silico} interactome is parsing through the MIPS database to select those 
clusters of proteins which agree with our definition of a protein complex. Therefore, for the MIPS repository, we have 
downloaded the three data files, two of which encapsulate the protein complexes and their composition. 

The first MIPS downloaded file, $complexcat.scheme$, consists of the hierarchical structure of the MIPS repository.
(maybe put a png of the file here or part of the file here???)  Each 
top level of this hierarchical structure represents some overall aggregate structure and each sub-structure (or 
inter-mediary structure) reflects some functional sub-group of the aggregate. This is the file for which we need to parse.

Our methodology for extracting protein complexes from the MIPS database is to search for three key terms within the
$complexcat.scheme$ file. The terms, (the word)
``complex'', and (the suffixes) ``-ase'' as well as ``-some'', provide an almost comprehensive search for the complexes
which will populate our \textit{in silico} interactome. The first term is self-explanatory while the latter two
need some elucidation. There are certain protein complexes which are well defined and exhaustively studied but do not
contain the word ``complex'' in its name (e.g. RNA Polymerase and Proteasome) which need to be incorporated into the
interactome. 

Parsing this data file is not limited only to differentiating those structures within our definition of a protein complex
from those structures outside. We also need to work within the restrictions and confines due to the limitations from the
experimental technologies. The bait to prey technologies such as AP-MS or Co-IP can only pull down aggregate protein
structures, and cannot demarcate between the various sub-structures. With this restriction at hand, our construction 
of the \textit{in silico} interactome does not include sub-structures that could not be identified with the available 
technology, i.e. sub-complexes will not be incorporated. (Footnote here saying that all sub-complexes from mips will
always be considered a sub-complex as per my comment above???) Under these restrictions, we were able 
to extract 141 protein complexes. 

After we have parsed through the file $complexcat.scheme$ and selected those protein clusters of interest, we use the 
second file, $complexcat_data_14112005$, to populate the individual protein complexes. Each row of $complex_data_11142005$
contain information concerning a single protein (many proteins are listed with multiplicity greater than one). The 
individual protein data consists of its protein complex membership (only one specific complex per row), MIPS specific
evidence codes describing the what methodologies were used to verify complex membership, and lastly the pubmed 
identification code for each protein. 

Unfortunately, merely taking the top level protein complex structure is not enough to guarentee the absence of 
sub-complexes. Once we have populated the protein complexes with their constituent protein members we can further
examine the complex to sub-complex relationship.
We have developed a method via the use of the Jaccard similarity coefficients to determine if a 
protein complex is contained wholly within another complex. The Jaccard index between two sets is defined
as the cardinality of their intersection quotient the cardinality of their union. If $A \subset B$, then the 
Jaccard similarity coefficient is $\frac{|A|}{|B|}$. If we let the protein complexes represent the sets of interest
we can, by examing all the 141 chose 2 set of Jaccard similarity coefficients,
systematically find all protein complexes which are contained in larger complexes. In this way, we have found
32 sub-complexes thus bringing the total number of protein complexes with which to populate the \textit{in silico}
inteactome from the MIPS repository to 109 unique protein complexes.

The third file, $evidencecat.scheme$, lists the MIPS evidence codes and matches the details for protein annotation within 
the protein complexes. (I don't use any evidence codes, so should we even write anything here in the paper?). 


\subsection{GO}

Gene Ontology (GO) began as a collaborative project to provide a single repository for the different database genomes. This 
repository is detailed by three bio-chemical ontologies: Biological Processes; Cellular Components; and Molecular Functions. 
For our purposes of building an \textit{in silico} interactome, it is beneficial to restrict our analysis to the Cellular 
Component ontology. Unlike the hierarchical structure of the MIPS repository, GO is organized as a directed acyclic graph 
(DAG). Additionally, the data from Gene Ontology is directly accessed via the R packages \Rpackage{GO} and 
\Rpackage{GOstats} rather than via downloaded files. 

The general methodology used to search for protein complexes in the GO repository is identical to those used in the MIPS
repository though the implementation is generally different. Much like the process of searching for protein complexes in the 
MIPS repository, we mine for the term ``complex'' and the
suffixes ``-ase'' as well as ``-some'' to search for the protein complexes by calling the ``grep'' and ``agrep''
functions. There is no need to manually populate the GO protein complexesbecause \Rpackage{GO} and \Rpackage{GOstats} have 
built in methods to populate the protein complexes.  Thus we have determined 208 unique 
GO nodes that corresponds to our given definition of a protein complex. 

Because of GO nodes are not built from smaller
constituent nodes, there is not a simple first step in filtering out sub-complexes.
Again we make use of the Jaccard similarity index to discern sub-complexes from 
aggregate ones. By investigating the 208 chose 2 derived Jaccard similarity indices, we 
have found that 28 GO nodes represent protein sub-complexes, and therefore, we are able to 
generate 180 unique GO protein complexes. 



\subsection{Experimental Data}

In this section, we describe the experiments conducted by Gavin, et al; Ho, et al; and most recently, Krogan, et al. All three experiments are based on the high-throughput techonology of complex purification followed by identification by mass spectroscopy. Each affinity purification - mass spectronomic (AP-MS) experiment yielded a tremendous wealth of bait to prey associations, but we must take these data points with care because high through-put data is known to repot high levels of error in addition to true associations between proteins. 

In each of the three datasets, bait to prey associations were inferred by using various kinds of the same methodology: an affinity based process to localize groups of proteins (the associated prey proteins) that have high probability of sharing some complex co-membership with the bait protein followed by a purification procedure to eliminate non-associated proteins which might haven been pulled down due to some stochastic elements and a protein complex identification process relying on mass spectroscopy. Gavin, et al used the procedure of tandem affinity purification (TAP) where the TAP tag is generated by polymerase chain reaction (PCR). Ho, et al used a version of immunoprecipitation which they have called high-throughput mass sprctrometric protein complex identification (HMS-PCI). Krogan, et al used a C-terminal tandem affinity purification (TAP) tagging. Because these three experiments are based on bait to prey association for protein complex identification, the raw data can be systematically and uniformly analyzed by \textit{apComplex} for estimation of protein complex composition.

Analysis by \textit{apComplex} transforms the problem of biological protein complex estimation to a problem of estimating the presence of directed edges in a protein-protein complex co-membership (PPCCM) graph. Recall that two nodes are adjacent in the PPCCM graph if they are co-members for any protein complex. Under such an imposed structure, the identification of protein complexes is equivalent to the identification of maximal cliques in the PPCCM graph. %%Confirm it has been shown that the exhaustive search for maximal cliques within a graph is $np-hard$ based on the number of nodes within the network. Independent of the complexity in maximal clique mining, the PPCCM graph derived from the AP-MS technologies contains errors by embedding false positive (FP) and false negative (FN) bait to prey associations. These errors translate to the addition of FP directed edges and the deletion of FN directed edges respectively %%need picture.

With the wet-lab experimental data, \textit{apComplex} searches for Bait to Hit (BH) maximal complete subgraphs (since maximal complete subgraphs are defined to be maximal cliques) which all recipricated bait-bait edges as well as all unreciprocated bait-hit-only edges exist. When such BH maximal subgraphs are found, \textit{apComplex} uses a statistical paradigm to determine the presence or absence of directed edges (particularly edges from hit-only proteins back towards those bait proteins which have unrecipricated association)
. The details concerning the statistical model upon which \textit{apComplex} is based can be found in \cite{Scholtens, Gentleman}.

The estimates derived from \textit{apComplex} can be divided into three groups. The MBME protein complex estimates are those derived from BH maximal subgraphs where multiple bait proteins (represented as nodes) and multiple edges (representing hits) are present. The SBMH protein complex estimates describe those complexes with only one single bait present but multiple hits (edges). Lastly, the UnRBB estimates consist of only two nodes (both bait proteins) where only one unreciprocated directed edge exists between them. It is quite clear that the MBME complexes have the highest probability of estimating true protein complexes since they are based on more biological information. For the construction of the \textit{in silico} interactome, we have elected to use only the MBME estimates because of its relative likelihood for accuracy.

Data from the AP-MS experiment have been filtered to yield protein complexes and stored in databases such as MIPS; the process for each experiment, however, is unique to each experiment. %%FixMe Each filtering process is based upon some statistical clustering paradigm that takes the underlying biological conditions with varing degrees. Without a uniform methodology to estimate protein complex co-membership, any \textit{in silico} interactome built from the estimated complexes would be suspect. \textit{apComplex} integrates a significant portion of the biological processes into its statistical model in estimating protein complexes. Thus by using \textit{apComplex} as the unique estimation algorithm, we can not only reduce the variability in confidence but also increase the overall confidence for the estimates of the protein complexes.


\subsection{Combining Estimates}

When estimates of the interactome are available from different sources
we must devise a method for combining them to provide a larger and
more general estimate. How we do this depends a bit on the estimates
themselves. We leave to another time a discussion of how to address
issues of sytematic and stochastic errors and rather consider the
problem of having two different estimates of an interactome that we
want to combine into a non-redundant joint estimate. The two different
estimates may come from different sources and hence could overlap by a
little or a lot. 

The so-called \textit{alignment} problem arises because some
complexes might not be labeled or are  unambiguously identified. The genes (or
proteins) that make them up, are well identified but the collections
are not. So, one of the first steps is to identify redundancy and to
eliminate it. For simplicity we presume that the complexes in one
estimate are labeled $C_1, \ldots, C_k$ and in the other
$K_1,\ldots,K_l$, where $k$ and $l$ are generally not the same.
We will discuss set theoretic relationships between the $C_i$ and
$K_j$ in terms of the proteins that constitute the complexes. Thus,
the statement, $C_i = K_j$, means that all proteins in $C_i$ are in
$K_j$ and the converse also holds. The statement, $C_i \subset K_j$
indicates that $C_i$ is a proper subset of $K_j$, that is, they are
not equal.

%%FIXME: could we look at the intersection of their respective PPI
%%graphs as a measure of concordance?

Complete concordance occurs when $C_i = K_j$, such complexes are
reasonably easy to identify and only one of them is retained. A
somewhat more difficult case is when $C_i \subset K_j$. For some
technologies we will retain $C_i$ and for others we want to retain
$K_j$. The user will have to specify which of the two alternatives
they want. Both cannot be retained due to identifiability
problems. %%FIXME: is this true - and do you have an example etc?

Since much of the data is derived from experimentation and the
underlying experiments tend to have high error rates (FIXME:citations
etc here) some consideration of near concordance must also be
considered. 

What measures will we use? What graphics/summary statistics can be produced?


\section{The estimate}

Discuss the estimate as we have it, how does it compare with other
estimates, what we know about etc. How many proteins, how many
complexes, etc.

Discuss some of the things that we could try and do with it


\section{Discussion}

What did we learn,

\end{document}
