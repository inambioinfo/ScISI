%
% NOTE -- ONLY EDIT ScISI.Rnw!!!
%
%\VignetteIndexEntry{ScISI Working Paper}
%\VignetteDepends{}
%\VignetteKeywords{Interactome}
%\VignettePackage{ScISI}
\documentclass{article}

\usepackage{hyperref}

\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textsf{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}



\newcommand{\classdef}[1]{%
  {\em #1}
}

\begin{document}
\title{Creating in Silico Interactomes}
\maketitle

\section{Introduction}

Protein complexes form a fundamental part of biology and are relevant
to our understanding of complex biological processes and to
deciphering the different roles played by genes and proteins.
A number of high throughput experiments have been carried out with the
goal of helping to better elucidate the nature and number of
interactions present \cite{Gavin, Ho, Krogan, Ito, Uetz}. We have
carried out a number of different investigations of these data
\cite{Scholtens, ScholtensVidalGent} which have focused on the
estimation of protein complex co-memberships. In our discussion we do
not distinguish between the term gene and the term protein, since the
available resolution is not fine enough and equating these concepts
leads to a more comprehensible dialog. The methodology is sufficiently
general to be able to address the more complex situation of different
protein/polypeptide variants should they arise.

In this paper we consider the problem of estimating an \textit{in
  silico} interactome. The role of the \textit{in silico} interactome
is to  provide a tool that can be used to carry out a variety of
computational experiments. These experiments will help to confirm the
viability of wet lab experimental procedures by allowing investigators
to alter experimental conditions (both stochastic and systematic
errors can be modified) and to measure how the outputs change as the
error rates do. Another purpose for the \textit{in silico} interactome
is to provide a tool that can generate multiple data sets, under
different conditions, so that the statistical properties of different
of proposed estimation procedures can be directly compared. A third
use for the \textit{in silico} interactome is to use it to help
develop tools and strategies for small scale experiments that will
probe the interactome at a very detailed level. For example, a
reasonable strategy to investigate a coherent set of protein complexes
is to first select a small number of candidates and explore their
interactions, say via affinity purification (co-precipitation)
experiments. Once the first experiment has been collected one would
like to analyze the data and determine an optimal, or nearly optimal
set of baits for future experiments. Finally, a fourth use of an
\textit{in silico} interactome is to study the effect of perturbations
in the network, such perturbations could be caused by evolution and
hence could become part of the study of evolutionary pressure on the
interactome, or they could be due to drug treatments and hence would
become part of a clinical investigation into the likely effects of
drug treatments.
%%FIXME: we could also mention studying the effects of sampling as yet
%%another use of the interactome.

Important design considerations include the fact that genomic science
is rapidly evolving and that new data sources will continuously come
on line. Hence there must be a mechanism by which the interactome can
be updated. There are many different and disparate data sources, there
should be some mechanism for incorporating all available
data. Different investigators will want to modify the interactome,
either with localy produced, but not yet public data, or to satisfy
personal beliefs. We have developed a paradigm that allows
investigators to create their own estimates, to share interactomes and
to build, revise and update interactomes.

We are aware of the very dynamic nature of protein interactions and
that different interactions occur at different times and under
different conditions. In this paper we consider the description of an
interactome, that can be thought of as representing the state of a
single type of cell (our example will be based on
\textit{S. cerevisiae} where there is a single cell, but where
different conditions could conceivably result in different
interactomes). We leave the problem of representing state-dependent
interactomes for a separate report.

In this paper we first describe the primary data sources used to
collect data for the interactome. We then describe how those data
sources are combined to provide a comprehensive interactome that can
be used as an input for the various computational tasks described above.

\section{Materials and Methods}

In this section we first describe what we mean by a protein complex
and describe different models for representing these data. We then
describe the process of creating an \textit{in silico} interactome
based on two public meta-data sources and three experimental data sets 
by combining purification of protein complexes with identification of their individual componenets via mass spectroscopy.


\subsection{What is a protein complex}

%%FIXME: a few pictures would surely help readers
A protein complex, for the purposes of this paper is two or more
proteins that physically interact for the purposes of carrying out
some biological objective. There is no need for all members of a
complex to interact with each other, but the graph connecting all
members where edges represent interactions must be connected.

We further note that some proteins will be involved in many complexes
while others will be involved in relatively few.

What should be said about sub-complexes? When sub-complexes exist
there can be identifiability problems that arise due to the technology
being used. FIXME: it would be good to give some sort of concrete
example of what might go wrong.

We have chosen to represent the protein complex co-membership graph as
a bipartite graph. The proteins themselves are represented by one type
of node while the protein complexes are the other. An edge goes
between a protein and each complex it is a member of. We note the
direct relationship between bipartite graphs and hypergraphs, and
shall make some use of that in our discussion.

\subsection{MIPS}

The MIPS comprehensive yeast genome database is a functional catalogue that provides tools to browse genome wide information for yeast. MIPS catalogues its database into twelve overlapping sections. The catalogue of interest for the construction of the MIPS derived \textit{in silico} sub-interactome is the $complex$ catalogue. 

Complications arise because the grouped proteins indexed in the $complex$ are too general and do not meet the standard definition of protein complex in its usual term. With this in mind, we downloaded two files and parsed the data into groups of proteins which did meet the standard definition for protein complex as stated before.

The first MIPS downloaded file, $F_1$, is a text file consisting of proteins, the MIPS protein complex ID for which they had membership, and the experiments used in their validation for complex co-membership. The second file, $F_2$ is a text file of that documents the titles for the general grouping of the proteins (collectively referred to as the complexes) along with an outline structure where sub-categories imply subsetting. Our strategy in determining protein complexes for the MIPS database is too mine for the exact term $''complex''$ in the $F_2$ file. Since we are interested in aggregate complexes, if the term $''complex''$ appears multiple levels of $F_2$, only the title of the highest level is recorded and its protein composition is determined from $F_1$. 

Mining for the term $''complex''$ is insufficient, for many protein complexes have specialized titles not including complex. In our search for protein complexes, we have also searched for terms suffixed with $-ase$ as well as with $-some$. In this case, those titles such as RNA Polymerase or Transcriptome will also be included in the formation of the interactome. 

The \textit{in silico} interactome is represented by a hyper-graph where the nodes correspond to proteins and hyper-edges correspond to protein complexes. After collecting the data from MIPS, we organize the collection of proteins into non-disjoint groupings corresponding to the hyper-edges. Each hyper-edge is catalogued so that we may identify the protein complex. In addition to the hyper-graph, we also create its associated hyper-graph incidence matrix where the rows are indexed by the proteins and the columns by the hyper-edges. 

The last item we create is a dataframe for the MIPS hyper-graph for the sake of record keeping. The dataframe contains three slots: name of the hyper-edge (the column names of the incidence matrix); the MIPS reference number; and the MIPS description (the title from file $F_2$). For ease of accessing the slots of the dataframe, an instance of the class \textit{yeastData} can be created. With this object, three methods have been written for which the hyper-edge name can obtain any one of the three: the MIPS reference number, the MIPS description, as well as the URL for additional data.  

We conclude this section with particular reasons why we have not chosen to take the protein complexes obtained by high through-put experimentation. Whereas the protein complexes we have thus selected for the \textit{in silico} interactome have been studied thoroughly (for these are the protein complexes MIPS has mined from the literature itself), those protein complexes given by high through-put experiments have little credibility since the methodology for determining complex composition is inconsistant from one experiment to the next and since each protein complex has been very little studied. Instead we have obtained the raw, unfiltered, and un-clustered bait to prey dataset from each individual experiment and analyzed the content via \textit{apComplex} in one consistent and uniform manner. An overview of \textit{apComplex} and the details of its analysis will be provided in a subsequent section. 

\subsection{GO}

Gene Ontology (GO) began as a collaborative project to provide a single repository for the different database genomes. This repository is detailed by three bio-chemical ontologies: Biological Processes; Cellular Components; and Molecular Functions. For our purposes of building an \textit{in silico} interactome, it is beneficial to restrict our analysis to the Cellular Component ontology. We begin the analysis of the GO repository by recalling that the structure of this database is that of a directed acyclic graph (DAG). In constructing the GO derived \textit{in silico} sub-interactome, we can select a rooted sub-graph from the Cellular Component DAG. The prominent node, $N$, is $GO:0043234$ which refers to the annotation $Protein Complex$. A neccessary (but sometimes insufficient) condition to finding all protein complexes indexed in the GO database is to find all the vertices incident to $N$, or in graph colloquy, all the vertices that are children on the node $N$. 

%%This needs to be discussed  - The insufficiency to this condition is one of logical semantics in the GO vocabulary. The notion of sub-complexes gives rise to complications. This instance is observed when a decendent of some child of $N$ is also directly incident to $N$ itself. For such a complex, $C$ that is directly (or indirectly) involved with other protein complexes, we need to make the choice of whether or not to include this complex in our \textit{in silico} interactome. For this purpose, the \texttt{getGoInfo} has a logical parameter \texttt{wantALLComplexes}. When search through the GO ontology for protein complexes, we can decide, for whichever conditions we impose on the \textit{in silico} interactome, to include or not to include those protein complexes analogous to protein complex $C$.

Much like the derived data from the MIPS repository, the GO data is collected and then arranged into a protein complex membership hyper-graph, and the hyper-graph is represented by its incidence matrix representation. We can also create a GO dataframe and an instance of the \textit{yeastData} class. 

It is important to note the distinction here between the differences between the selection criteria for incoporating data from the MIPS database and those for the GO database. Recall that data selection for MIPS relied on word mining, in particular, for the term $complex$ and terms suffixed by $-ase$ or by $-some$. Protein complexes such as DNA polymerase and %%FIXME transcriptsome might not be selected with a simple word search for $complex$, but these same complexes %%True? would be annoated as protein complexes in the GO database.


\subsection{Experimental Data}

In this section, we describe the experiments conducted by Gavin, et al; Ho, et al; and most recently, Krogan, et al. All three experiments are based on the high-throughput techonology of complex purification followed by identification by mass spectroscopy. Each affinity purification - mass spectronomic (AP-MS) experiment yielded a tremendous wealth of bait to prey associations, but we must take these data points with care because high through-put data is known to repot high levels of error in addition to true associations between proteins. 

In each of the three datasets, bait to prey associations were inferred by using various kinds of the same methodology: an affinity based process to localize groups of proteins (the associated prey proteins) that have high probability of sharing some complex co-membership with the bait protein followed by a purification procedure to eliminate non-associated proteins which might haven been pulled down due to some stochastic elements and a protein complex identification process relying on mass spectroscopy. Gavin, et al used the procedure of tandem affinity purification (TAP) where the TAP tag is generated by polymerase chain reaction (PCR). Ho, et al used a version of immunoprecipitation which they have called high-throughput mass sprctrometric protein complex identification (HMS-PCI). Krogan, et al used a C-terminal tandem affinity purification (TAP) tagging. Because these three experiments are based on bait to prey association for protein complex identification, the raw data can be systematically and uniformly analyzed by \textit{apComplex} for estimation of protein complex composition.

Analysis by \textit{apComplex} transforms the problem of biological protein complex estimation to a problem of estimating the presence of directed edges in a protein-protein complex co-membership (PPCCM) graph. Recall that two nodes are adjacent in the PPCCM graph if they are co-members for any protein complex. Under such an imposed structure, the identification of protein complexes is equivalent to the identification of maximal cliques in the PPCCM graph. %%Confirm it has been shown that the exhaustive search for maximal cliques within a graph is $np-hard$ based on the number of nodes within the network. Independent of the complexity in maximal clique mining, the PPCCM graph derived from the AP-MS technologies contains errors by embedding false positive (FP) and false negative (FN) bait to prey associations. These errors translate to the addition of FP directed edges and the deletion of FN directed edges respectively %%need picture.

With the wet-lab experimental data, \textit{apComplex} searches for Bait to Hit (BH) maximal complete subgraphs (since maximal complete subgraphs are defined to be maximal cliques) which all recipricated bait-bait edges as well as all unreciprocated bait-hit-only edges exist. When such BH maximal subgraphs are found, \textit{apComplex} uses a statistical paradigm to determine the presence or absence of directed edges (particularly edges from hit-only proteins back towards those bait proteins which have unrecipricated association). The details concerning the statistical model upon which \textit{apComplex} is based can be found in \cite{Scholtens, Gentleman}.

The estimates derived from \textit{apComplex} can be divided into three groups. The MBME protein complex estimates are those derived from BH maximal subgraphs where multiple bait proteins (represented as nodes) and multiple edges (representing hits) are present. The SBMH protein complex estimates describe those complexes with only one single bait present but multiple hits (edges). Lastly, the UnRBB estimates consist of only two nodes (both bait proteins) where only one unreciprocated directed edge exists between them. It is quite clear that the MBME complexes have the highest probability of estimating true protein complexes since they are based on more biological information. For the construction of the \textit{in silico} interactome, we have elected to use only the MBME estimates because of its relative likelihood for accuracy.

Data from the AP-MS experiment have been filtered to yield protein complexes and stored in databases such as MIPS; the process for each experiment, however, is unique to each experiment. %%FixMe Each filtering process is based upon some statistical clustering paradigm that takes the underlying biological conditions with varing degrees. Without a uniform methodology to estimate protein complex co-membership, any \textit{in silico} interactome built from the estimated complexes would be suspect. \textit{apComplex} integrates a significant portion of the biological processes into its statistical model in estimating protein complexes. Thus by using \textit{apComplex} as the unique estimation algorithm, we can not only reduce the variability in confidence but also increase the overall confidence for the estimates of the protein complexes.


\subsection{Combining Estimates}

When estimates of the interactome are available from different sources
we must devise a method for combining them to provide a larger and
more general estimate. How we do this depends a bit on the estimates
themselves. We leave to another time a discussion of how to address
issues of sytematic and stochastic errors and rather consider the
problem of having two different estimates of an interactome that we
want to combine into a non-redundant joint estimate. The two different
estimates may come from different sources and hence could overlap by a
little or a lot. 

The so-called \textit{alignment} problem arises because some
complexes might not be labeled or are  unambiguously identified. The genes (or
proteins) that make them up, are well identified but the collections
are not. So, one of the first steps is to identify redundancy and to
eliminate it. For simplicity we presume that the complexes in one
estimate are labeled $C_1, \ldots, C_k$ and in the other
$K_1,\ldots,K_l$, where $k$ and $l$ are generally not the same.
We will discuss set theoretic relationships between the $C_i$ and
$K_j$ in terms of the proteins that constitute the complexes. Thus,
the statement, $C_i = K_j$, means that all proteins in $C_i$ are in
$K_j$ and the converse also holds. The statement, $C_i \subset K_j$
indicates that $C_i$ is a proper subset of $K_j$, that is, they are
not equal.

%%FIXME: could we look at the intersection of their respective PPI
%%graphs as a measure of concordance?

Complete concordance occurs when $C_i = K_j$, such complexes are
reasonably easy to identify and only one of them is retained. A
somewhat more difficult case is when $C_i \subset K_j$. For some
technologies we will retain $C_i$ and for others we want to retain
$K_j$. The user will have to specify which of the two alternatives
they want. Both cannot be retained due to identifiability
problems. %%FIXME: is this true - and do you have an example etc?

Since much of the data is derived from experimentation and the
underlying experiments tend to have high error rates (FIXME:citations
etc here) some consideration of near concordance must also be
considered. 

What measures will we use? What graphics/summary statistics can be produced?


\section{The estimate}

Discuss the estimate as we have it, how does it compare with other
estimates, what we know about etc. How many proteins, how many
complexes, etc.

Discuss some of the things that we could try and do with it


\section{Discussion}

What did we learn,

\end{document}
