%
% NOTE -- ONLY EDIT ScISI.Rnw!!!
%
%\VignetteIndexEntry{ScISI Working Paper}
%\VignetteDepends{}
%\VignetteKeywords{Interactome}
%\VignettePackage{ScISI}
\documentclass{article}

\usepackage{hyperref}
\usepackage{natbib}
\usepackage{subfigure}
\usepackage{graphicx}
\usepackage{amsmath,pstricks,fullpage,amsthm,amssymb}




\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textsf{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}



\newcommand{\classdef}[1]{%{\em #1}
}
\newtheorem{Lem}{Lemma}


\begin{document}
\title{Creating an Silico Interactome}
\maketitle

\section{Introduction}

Understanding protein interactions is relevant to our understanding of
complex biological processes and to deciphering the different roles
played by genes and proteins. In particular developing a set of maps
that associate proteins with multi-protien complexes will be an
essential step to this process. A number of high through-put
experiments have been carried out with the goal of helping to
elucidate these nature and number of their occurances \citep{Gavin,
  Ho, Krogan, Ito, Uetz, Giot}. Yet our knowledge remains
incomplete. Such experiments, while valuable, are expensive and time
consuming to carry out. This suggests that simulation models may be
beneficially employed to identify the viability of experimental
procedures, to aid in integrating data from disparate sources, and to
provide a sound basis for the development of new methodology in
designing experiments and in analyzing the resultant data. In this
paper we outline one approach in the creation of \textit{in silico
  interactomes} that would be suitable for such simulation
experiments. 

We consider the problem of estimating \textit{in
  silico} interactomes (ISI) for \textit{Saccharomyces cerevisiae} and
we describe five different roles where such a computational device can
be used.  First, the ISI provides a tool that can be used to mimic
wet-lab experiments; these \textit{in silico} experiments can help to
confirm the viability of the wet-lab experimental procedures by
allowing investigators to alter experimental conditions (by the modification
of both stochastic and systematic error rates) and then measure how
the outputs change as the error rates do. Second, the ISI provides a
tool from which multiple data sets can be generated, under different conditions,
so that the statistical properties of different proposed estimation
procedures can be directly compared. A third use for the ISI is to use
it to help develop tools and strategies for small scale experiments
that can probe the interactome at a very detailed level. For example,
a reasonable strategy to investigate a coherent set of protein
complexes is to first select a small number of candidates and explore
their interactions, say via affinity purification (co-precipitation)
experiments. Once the first experiment has been collected one would
like to analyze the data and determine an optimal, or nearly optimal
set of baits for future experiments. A fourth use of an ISI is to
study the effect of perturbations in a network.  Such perturbations
could be caused by evolution (and hence could become part of the study
of evolutionary pressure on the interactome) or due to drug treatments
(and hence would become part of a clinical investigation into the
likely effects of drug treatments). The fifth use for such a tool is
to explore and understand the effects of different sampling paradigms
on the inferences that can drawn from different wet-lab
experiments. We note that there are a number of recent papers
\citep{Oltavi,Goverview, SubsampNetworks} that raise many important
issues in this regard.

An ISI is not without its limitiations. It cannot reveal new
relationships between its members, but rather can only reflect the
current state of biological knowledge. It can, however, be used in any
of the five tasks listed above and the outputs of the computational
experiments will often provide predictions of real interactions that
could be tested. Further, one type of interaction can be used either
to predict or to model other types of interactions, and provide
information about the likelihood of interactions; the verification of
interactions remains the domain of experimental biology.

Protein interactions are dynamic by nature so that different
interactions occur at different times and under different
conditions. For example, some protein complexes such as those needed
to facilitate cell division are often transient in nature appearing
when needed and dissovling when no longer required, whereas other
complexes such as the ribosome (and its subunits) are essentially
permanently constituted.  We provide some tools that will allow
investigators the ability to indicate situations and conditions under
which an interaction is known to occur and we discuss a paradigm where
an investigator will be able to select all interactions for a given
condition. 

%%I if we are going to validate the interactome we are building, should
%%we not regulate the estimate behind the method?? -- TC
While the estimated interactome is itself of some great interest, we
note that it is more important to describe the procedure by which an
ISI is produced. There are many reasons why the estimate is of less
importance, among them the fact that the methodology can be applied to
many organisms and tissue types to yield specialized ISI estimates. We
also note that the data used in the construction is constantly being
updated and improved, hence users will want to regularly update any
estimate as new data sources become availble, or old ones are
updated. Hence, to be viable there must be a mechanism for
updating and refining the ISI. We also note that there are many
different and disparate data sources and the system should be
sufficiently flexible to allow users to select data sources
appropriate for their studies as well as the ability to incorporate
additional data from new and potentially different experimental
techniques. Finally we note that investigators will often want to
modify the ISI, either with locally produced, though not yet public,
data, or to satisfy personal beliefs. The paradigm we describe here
allows investigators to create their own personalized estimates, to
share interactomes and to revise and update interactomes.

In this paper we first define the notion of a biological interactome
and give various examples of such interactomes. We then present a set
of computational tools, embodied in the \Rpackage{ScISI} package, that
we have assembled to construct the \textit{in silico interactome}. The
general steps that must be carried out are, first assembling the data
that are to be used for the construction and second to process those
data into an estimated interactome that can be used as an input for
the various computational tasks described above. Finally we report on
some \textit{in silico} experiments that can be performed using the
estimated interactome.


\section{Preliminaries}

In our discussion we do not distinguish between the term gene and the
term protein, since the available resolution is not fine enough and
equating these concepts leads to a more comprehensible dialog. The
methodology is sufficiently general to be able to address the more
complicated situation of different protein/polypeptide variants should
they arise.

\subsection{Biological Interactomes}

In the broadest sense, an interactome is a set of elements $P$, for
our purposes $P$ is the set of genes, or their related proteins,
within a particular organism or cell type. The elements of $P$ have a
variety relationships with each other and each of these different
relationships can be modeled using some form of graph. Some
relationships are binary, for example, protein $p_1$ is known to
directly physically interact with some other protein, $p_2$, perhaps
under a specific set of conditions. In other cases, the relations are
not binary but rather are one to many or many to many. The example we
use for this second type of relationship is that of protein complex
membership. In this setting all members of a complex are related to
each other, but they need not directly interact and the relationship
is not binary. A reasonable model for such data is as either a
hypergraph \cite{Berge} or, equivalently, the bipartite graph
representation. Proteins are grouped into sets according to whether
they are in a complex and these sets constitute the hyperedges of the
hypergraph. There is no need for the hyperedges to be disjoint and
proteins can be in many or few hyperedges, depending on whether the
protein is in many or few complexes.

We begin by distinguishing between many different types of
interactomes with a few general comments, we will make the
terms and ideas more explicit in later sections of this report. There
are interactomes that model direct binary interactions and hence are
related to experiments using the yeast two hybrid (Y2H) system
\citep{Y2H, Ito, Uetz}. A second type of interactome is one that
models protein complex membership. In this model, two proteins are
said to interact if they are constituent members of some protein complex 
under the conditions of interest. This second type of interactome is
more closely related to co-precipitation or affinity-purification
experiments \citep{Ho, Gavin, Krogan}. We note that proteins which
interact in the second sense, need not interact in the first sense;
hence, we separate these two different, but related, concepts. Other
interactomes can be created by considering other relationships such as
those between transcription factors and their direct targets or the
interaction network that can be defined on pairs of synthetically
lethal genes \citep{Tong2004}.

We can put these concepts into a more biological framework as
follows. Let $P$ denote the expressed genome of some cell or tissue,
and hence each such gene is represented by a node in our graph. Any
two genes that have either a direct biochemical or biophysical
interaction will have an edge between them. We remark that a gene may
be associated with itself if it induces a homodimer and such an
observation would be represented by a self-loop in the graph. 
Next, we consider a different set of relationships which are those of
protein complex co-membership. In this, different graph, we again
represent the genes as nodes, but now edges are determined by whether
or not the two proteins are found as  constituent parts of some
protein complex. If represented in this way there is a strict loss of
information, since a graph can only represent binary relationships yet
protein complex membership is a many-to-one relationship. For this
reason we prefer the hypergraph since in this format all important 
information is conserved.

\begin{figure}
\centering
\subfigure[Protein Binary Interaction Network]{
\includegraphics[width = 65mm]{../extdata/protein_network_large.jpg}}
\caption{A protein binary interaction network as a graph and protein complex
membership network rendered as a bi-partite graph FIXME - Cannot use this as it is
probably copyrighted, but wanted to put here as example...need to render one 
ourselves}
\end{figure}


These two biological interactomes are related, but they are also
distinct, and the use of the data in modeling and other downstream
uses requires that some caution be used to not confuse the
concepts. It is certainly the case that for our working definition of
a protein complex the members of that complex will have some binary
interactions with other members. But not all members have direct
physical interactions with other members, so we would not use a
so-called \textit{matrix} model to
represent those interactions. These two examples highlight the subtle
differences between two distinct interactomes and underscores the
necessity to keeping distinct interactomes separate. We will refer to
the first of these interactomes as $I_b$, where the $b$ subscript
reinforces the notion that binary relationships are being modeled and
the second as $I_c$ where the $c$ subscript reinforces the notion that
protein complexes are being modeled.

There are of course many limitations to such an approach, however,
there will be ample opportunity to refine and revise the models
proposed here as our knowledge of the underlying biology improves and
as the available computer technology improves. Among the limitations
is the observation that some interactions will only take place under a
specific set of conditions, and that other interactions, sometimes
involving the same proteins, will occur under other conditions. Thus,
the model representing these data will need to become richer and to be
able to indicate under which conditions a given relationship is known
to occur. Some interactions are specific to certain tissues (in higher
organisms) or to particular phases of the cell cycle, and so on. The
models we propose can be extended in fairly straightforward ways to
encompass these details, but the available data are currently to
sparse to warrant such an approach. We will note some experiments, and
some uses of existing experimental data, that can provide some
insight. 

In this paper, we will report on a set of methodological tools that
can be used to construct an \textit{in silico interactome}
for \textit{S. cerevisiae}. We restrict our attention to the two
interactomes described above, $I_b$ and $I_c$. As we noted above, not
all complexes are present at all times in the cells under study, but
we are unable to model this aspect due to the lack of
appropriate data on which to base such classifications. When such data
become more widely available they can easily be accomodated within the
paradigm we are proposing.

We first define what we mean by a protein complex and describe
different models for representing these data. Then we explain the 
relationship of binary interactions within this working definition of 
a protein complex. Next we give a concise
description of the computational tool \textit{ScISI} and show its
dynamic properties in constructing different complex membership
interactomes and binary interactomes. We then describe the process of 
creating an \textit{in silico} protein 
complex interactome via \textit{ScISI} based on two
public meta-data sources and three experimental data sets by combining
purification of protein complexes with identification of their
individual components via mass spectroscopy. In addition we consider the
construction of an \textit{in silico} binary interactome based
primarily on data from IntAct, which is itself based on high
throughput experimental data assayed by the Yeast 2-Hybrid (Y2H) technology.
The IntAct repository currently has fourty-one Y2H data-sets which 
are parsed and processed in creating the binary interactome.

%% (FIXME: list the yeast data here) ... can you explain which data you
%% would like listed...certainly not all of the y2h data?  

\subsection{Protein complexes: Definition, Representation and Characteristics}

%%FIXME: a few pictures would surely help readers - how are we making
%%out on that?
% Working on it - TC


We define a protein complex to be two or more proteins that creates one 
functional unit for the purposes of carrying out some biological
objective. This functional unit is the sum total effects of the binary 
interactions amongst the constituent members. 
There is no need for all members of a complex to physically
interact with one another, but all the proteins do need to
combine to form a connected multi-protein structure. In essence, a protein
complex is a biological collection of affiliated proteins assembled via 
binary interactions. We remark that some proteins
will be involved in many complexes while others will be involved in
relatively few. Protein complexes range in size from two proteins to
more than fifty.

Having determined a working definition, we describe the mathematical 
representations chosen for binary interactions as well as for protein 
complexes in this paper.

\subsubsection{Graphs and HyperGraphs}

We require a small amount of graph theory to allow for succinct
discussion of the relevant concepts. A graph $G$, consists of a pair
of sets; the vertices, or nodes, $V$, and the edges, or relations,
$E$. We write $G=(V,E)$. Graphs can be used to represent binary
relationships and hence are an appropriate model and data structure
for $I_b$. They cannot represent the more complicated situation of
modeling protein complex co-membership. In this case we require the
use of hypergraphs \cite{Berge}. A hypergraph, $H$, consists of a set
of nodes, $V$, and a set of hyperedges. A hyperedge is any subset of
$V$. Thus, for modeling protein interaction data the vertex set is the
set of proteins in the organism or tissue under study. To represent binary
relationships we will use a graph, where the edges indicate the
presence of a binary interaction and for complex co-membership data we
will use a hypergraph, where the hyperedges are the identities of the
proteins that constitute the complex. There is a one-to-one
relationship between hypergraphs and bipartite graphs and in some
reports bipartite graphs are used.

There are a variety of different representations for both graphs and
hypergraphs. We will mainly make use of the incidence matrix
representation for $H$ and the adjacency matrix representation of $G$.
For the protein complex hypergraph the
incidence matrix representation, $M_B$, is a $\{0,1\}$-matrix where
proteins index the rows and protein complexes index the columns. The
$(i,j)$ entry for $M_B$ is one if protein $p_i$ is a constituent
member of complex $c_j$; the entry is zero otherwise. When studying
binary interactions the representation will be of a graph, and then
the adjacency matrix is typically square (or upper triangular) with
the proteins indexing both the rows and the columns. In this matrix a
one in position $(i,j)$ indicates that protein $p_i$ interacts with
protein $p_j$. This matrix is likely to be sparse and we will make use
of appropriate software tools and data representations.

<<getGraph, echo=FALSE, results = hide>>=
library("ScISI")
library("Rgraphviz")
data(arp23G)
data(nAt)
pdf("arp23Graph.pdf")
plot(arp23G, "dot", nodeAttrs = nAt)
dev.off()
@ 

\begin{figure} 
\centering
\subfigure[Atomic rendering of ARP 2/3 labelled by common names.]{
\label{arp23Physical}
\includegraphics[width = 75mm]{../extdata/Arp2_3_complex.png}}
\subfigure[Graphical rendering of ARP 2/3 identified by crystallography 
labelled by the systematic names.]{
\label{arp23Graph}
\includegraphics[width =75mm]{arp23Graph.pdf}}
\caption{Some scientists might find the physical rendering of ARP 2/3 to be
of more use while others might prefer a graphical representation. We note that
the issue of identifiability presents itself as creator of the atomic rendering
has chosen one version of the common names while the creator of the graph has
chosen the systematic gene names. The coloring scheme provided allows for one
to one matching of proteins from one rendering to the other.}
\end{figure}

\subsubsection{Protein Sub-Complexes}

There are sure to be situations where a protein complex, that exists
under one set of conditions, is a proper subset of a complex that
exists under another set of conditions. For some analyses it will be
important to remove those complexes which are proper subsets of other
complexes and we provide tools to help do that.

%%Maybe this example can be an done as a footnote with some pictures 
%%of how APMS cannot but pull out the largest cluster since that is
%%the limitation of the technology. I am thinking of using RNA Pol II 
%%holenzyme including RNA Pol II

One example is protein complex estimation using data collected from 
Affinity Purification - Mass Spectrometry (AP-MS) experimentation (wet-lab 
or in silico). Recall that in the AP-MS experiments, bait proteins are
placed in vivo so that they may generate clusters with any proteins known
to be co-members. In such an experiments, sub-complexes (if they are 
known to exist) cannot be assayed due to the limitations of the technology.

With the AP-MS limitations in mind, estimation algorithms cannot detect
the composition of sub-complexes. Therefore, if in silico experiments are
conducted with complex estimation as the goal, it is unnecessary (in fact
in-efficient) to retain protein sub-complexes in the \textit{in silico}
interactome.

%FIXME: it would be good to give some sort of concrete
%example of what might go wrong.

%%FIXME: somewhere we need a discussion of the need to fix on a common
%% set of gene names. Otherwise downstream analyses become really problematic
%% OK - TC

\subsubsection{Protein (Complex) Identifiability}

For a protein complex to be uniquely identifiable, it is necessary for each 
of the constituent protein members to be uniquely identifiable. Unfortunately,
this is not always true. Currently there are two main methods of identifying
proteins: 1. either using the locus name (common/alias name) for the protein or 2.
using the ORF name (systematic name) for the gene. We remark that in addition
to these two methods, many data repositories have their own system of 
nomenclature, though they all seem to be derived from one of the two main 
methods, so we will contain our discussion between the translation of these 
two main nomenclatures.

%%I am going to create a table that will give these examples in a more
%%meaningful way.

\begin{table}
\centering
\label{geneNames}
\begin{tabular}{|l|p{0.65\textwidth}|}
\hline
Gene Gommon Names&Corresponding Gene Systematic Names\\
\hline
YRF1&YER190W, YDR545W, YGR296W, YLR466W, YLR467W, YNL339C, YPL283C\\
YPK1&YKL126W, YJL093C, YNL307C\\
POT1&YIL160C, YKL198C\\
ZRG11&YIL046W, YOR030W\\
RTS1&YOR014W\\
\hline
Gene Systematic Names&Corresponding Gene Common Names\\
\hline
YPL084W&NPI3, ASI6, VPS31, LPF2\\
YIL148W& UB11, UBI1, CEP52A\\
YNL041C& SEC37, COD2\\
YGR028W& YTA4\\

YHR133C&NA\\
YPL170W&NA\\
\hline
\end{tabular}
\caption{The correspondance between Gene Common Names and Gene Systematic Names. Notice
that the correspondance can be many to one in both instances, and notice that the 
correspondance can also be undefined.}

\end{table}



Thus determining protein complex composition and protein binary interactions
becomes problematic if different 
investigators chose to use differing systems of nomenclature. For our purposes, 
we have chosen to use the ORF names to identify proteins exclusively, and we discuss
our methods for overcoming the identifiability problems in the following sections. 

\section {Methodology}

\subsection*{Constructing the Interactomes}

The construction of the \textit{in silico} interactomes is constrained by the 
characteristics listed above. To build the binary interactome, $I_b$, is equivalent
to constructing the binary interaction adjacency matrix while maintaining 
identifiability of the proteins at hand. In addition to maintaining 
identifiability, building the protein complex interactome, $I_c$, is equivalent to 
constructing the corresponding complex membership incidence matrix while establishing
conditions which determines the retention of sub-complexes. 

The following sections provide the detailed description of the tools developed and 
the steps taken to creating the respective \textit{in silico} interactomes. 

\subsection{Protein Complex Interactomes}

We first discuss the creation, or estimation of $I_c$. Our basic
strategy is to assemble a number of software tools, together with
available data, from databases or experimental results. We process the
data from each database or experiment separately and then sequentially
integrate the different protein complex estimates into an estimate.
Some investigators may want to restrict their attention to well-known
and documented complexes while others will be interested in exploring
likely complex co-memberships. For this reason we construct two
estimates of $I_C$ in yeast. One is based only on complexes reported
in GO and MIPS \citep{GO, GOA}, while the other extends this first
estimate to include data from high through-put co-precipitation
experiments. 

We remark that the complexes documented within GO and MIP are
based on many different technologies such as small scale protein
complex verification experiments. Many of these protein complexes have
been exhaustively verified. 

The choice of input data sources and the manner in which they are
processed is subjective and different investigators are likely to make
different decisions. We report the sources that we used and the
decisions made; others can easily make use of alternative or
additional sources. We make use of two rather distinct data sources,
one is the set of published and annotated protein complex data that
can be obtained from the Gene Ontology (GO), \citep{GO, GOA},
(\url{www.geneontology.org}) and the Munich Information Center for
Protein Sequences (MIPS). Additionally we will make use of protein
complex estimates from three publicly available wet-lab experiments
\citep{Ho, Gavin, Krogan}. Rather than make use of these data
directly, we first apply the technology of \citep{Scholtens,
  ScholtensVidalGent} since, as demonstrated in those references, the
resultant data are more consistent with known biological complexes.

%%Overall approach: these sources have textual descriptions of
%% sets of genes and in some cases the sets of genes represent complexes
%% in the absence of a data source provided set of complexes we search
%% the terms for keywords, we also carried out different hand curations
%% to include other terms that had not been picked up by this approach

\subsubsection{Obtaining Protein Complex Membership Information from Data Repositories}

%%FIXME: the numbers in here should be part of an \Sexpr and be
%%computed from the actual data - otherwise why are we using a
%%vignette? 

<<getCompData, echo=FALSE, results=hide>>=
library("ScISI")

@ 

In searching for and parsing through information from the two online 
data repositories, GO and MIPS, we used somewhat indirect methods. 
For the GO data source, we made use of the Bioconductor metadata package 
\Rpackage{GO} which contains the pertinent information. 
There does not exist a R metadata package for the MIPs data source, so
we downloaded three files from its repository. The file \textit{complexcat.scheme}
details the hierarchy classification structure of the MIPs protein 
complexes, and the \textit{complexcat\_data\_14112005} file has the 
protein annotations and evidence codes for each protein complex. We note that the 
latter file is suffixed with an eight digit number which indicates the 
day/month/year which this file is updated (there is a bi-annual update 
for this file). The last file is the \textit{evidencecat.scheme} which 
contains the evidence code definitions. 

For each data repository, the textual terms used to describe its
contents are parsed for specific key words. While Making use of regular
expression searches and approximate matching regular expression
searches, we have searched for all the terms that contain one of the 
three default character strings listed:

\begin{enumerate}
\item  the exact word \texttt{complex};
\item one or more words that end with the suffix \texttt{ase};
\item one or more words that end with the suffix \texttt{some}.
\end{enumerate}

In particular we use the following three regular expression,
\verb+complex+, \verb+\\Base\\b+, and \verb+\\Bsome\\b+ in our search.
These narrow the pool of return values yet include terms such as
\texttt{DNA-directed Polymerase II holoenzyme} or 
\texttt{repairosome}. 

Users can modify the search criteria to add new terms or to remove any
of those default values listed above. Terms selected correspond to
protein complexes and these are then collected and the corresponding
incidence matrix is computed. We note that both the GO and the MIPs 
repositories annotate proteins by their systematic gene names, and so
the incidence matrix computed has the rows are indexed by the systematic
gene names and the columns by the protein complex identification 
codes (unique to each repository).

We remark that even with the limited return values, the restrictions imposed 
by the regular expression searches will still contain elements which we do not 
consider protein complexes. Care must be taken to inspect those obtained 
elements from each repository. 

Elements such as arginase, and CTP synthetase are considered by some to be 
protein complexes even though they contain one unique protein. Because the 
data repositories do not include information such as multiplicity, we have 
decided to remove any unital protein complexes since it does not meet the
requirements we have established. In addition, some elements such as (FIXME - 
look up some examples) are the names of polypeptides and not protein complexes, 
so they too must be removed from the selected data. 

In addition to those exceptions we have just mentioned, the regular expression 
parsing methodology also obtains those protein complexes derived from high 
through-put AP-MS experiments and estimated by each respective experimental
investigator. Presently, only the MIPS data repository annotates proteins by 
these high through-put experiments. In constructing the protein complex 
interactome, we have elected not to retain those complexes whose constituent 
members are annotatated in this manner.

There are several reasons why we dis-allow the inclusion of these protein 
complexes. One is the lack of uniformity by which these complexes were estimated;
this lack of uniformity creates problems in the analysis and validation to 
the interactome. Another reason is is the estimation algorithms themselves; previous
analysis \citep{Scholtens, ScholtensVidalGent} of the resulting protein complexes 
annotated by high through-put experiments shows that in general, the protein 
complex size tend to be over-estimated, i.e. the overall size distribution
is higher than that of the set of well known protein complexes. Lastly, high 
through-put data is known to have a larger incidence of error than that of small
scale systematic experiments, and therefore, caution needs to be taken when 
dealing with these particular putative protein complexes.

Realizing that there are elements extracted from the data-bases which need to be
dis-allowed, we address the systematic and computational methods in excluding individual 
proteins as well as entire protein complexes. Both GO and MIPS provide additional 
information on the curation and
provenance of the data that they report. This information comes in the
form of evidence codes, which are used by both resource, although the
codes themselves are unique to the different resources. Users can
specify a list of evidence codes and dis-allow those proteins whose
annotations are found in the supplied list. Table~\ref{goAndmipsECode} lists both 
the GO and MIPs evidence codes we have used to reject protein membership in 
the various complexes we have extracted:


%%FIXME: name names or drop this
%%Done - TC
%While repositories such as Mips and GO will annotate proteins to each
%complex and store this data by these annotations, there is a small number 
%of repositories such as the \Rpackage{apComplex} package of the Bioconductor
%project which store the bi-partite graph incidence matrix for the 
%protein complex composition data. For repositories such as \Rpackage{apComplex},
%we can simply download these matrices.

%\subsection{Processing Online Repositories}
%%FIXME: I don't think it is the right name - 
%% one distinction is those repositories where there are 
%% sets of genes with text descriptions, only some sets are complexes
%% and we need to extract them. Other repositories have protein
%% complex predictions - then we don't need searching. Are there
%% examples of the second type?
\begin{table}[htp]
\label{goAndmipsECodes}
\centering
\begin{tabular}{|l|p{0.65\textwidth}|}
\hline
GO Evidence Codes&GO Evidence Code Definitions\\
\hline
IEA&Inferred from Electronic Annotation\\
NAS&Non-traceable Author Statement\\
ND&No Biological Data Available\\
NR&Not Recorded\\
\hline
Mips Evidence Codes&Mips Evidence Code Definitions\\
\hline
901.01.03&Overview information (TAS/NAS)\\
901.01.03.01&Review\\
901.01.03.02&Text-book\\
901.01.04&Personal communication (TAS/NAS)\\
901.01.04.01&Homepage (Web)\\
901.01.04.02&E-mail\\
901.01.05&Closed information (NAS)\\
901.01.05.01&Institution\\
901.01.05.02&Private\\
902.01.01.02.01.01&Co-immunoprecipitation\\
902.01.01.02.01.01.01&Co-immunoprecipitation, native\\
902.01.01.02.01.01.02&Co-immunoprecipitation, epitope tag\\
902.01.01.02.01.02&Affinity chromatography\\
902.01.01.02.01.02.01&Affinity chromatography, native\\
902.01.01.02.01.02.02&Affinity chromatography, affinity-tag\\ 
902.01.01.04.01&Mass spectrometry (MS)\\
902.01.01.04.01.01&MS with in-line two-dimensional liquid chromatography (MudPIT)\\
902.01.01.04.01.02&MS with liquid chromatography coupled to tandem mass spectrometry (LC-MS/MS)\\
902.01.01.04.01.03&MS with matrix-assisted laser desorption/ionization time-of-light (MALDI TOF MS)\\                         
902.01.01.04.02&Immuno detection\\
901.01.09.02&High throughput experiment\\
\hline
\end{tabular}

\caption{This table details the GO evidence codes as well as the MIPs evidence codes. 
Presently, only the MIPs data repository has annotated genes/proteins via high 
through-put experimental data; these are the evidence codes prefixed with by 902.}
\end{table}

For the GO data repository, only four evidence codes were used to reject protein membership. 
Any protein having only these four evidence codes to support its annotation is considered 
suspect, and we have chosen to remove them from the data. The MIPs evidence codes that are 
selected is divided into two groups: 1. those that are prefixed by 901 and 2. those that are
prefixed by 902. Similar to the chosen GO evidence codes, the MIPs evidence codes beginning 
with 901 refer to non-experimental methods of inference. Indeed, some of the MIPs codes 
are similar enough to the GO codes that the curators of MIPs have referenced some GO evidence
codes when pertinent. The Mips evidence codes beginning with 902, however, refer to 
experimental methods of inference and annotation. Because we have chosen to reject any estimates
based on high through-put AP-MS experiments, we have selected any MIPs evidence code that
corresponds to any high through-put technology. 

Unfortunately, the use of evidence codes is not enough. Even with the selected evidence
codes listed above, a large number of high through-put putative protein complexes are 
still retained. In the addition to the evidence codes, we also make use of the MIPs hierarchy
class system in which proteins complexes are grouped. The MIPs data repository groups 
protein complexes by their functionality, and because the putative, high through put 
protein complexes have yet to be validated nor been studied, they are grouped into one
separate category. This category has a unique prefix code (550), and so we can simply reject
any protein complex that has a prefix code 550. 

As we have mentioned earlier, the functions of ScISI do have limitations, and so 
unwanted protein clusters will inevitably make their way into the data-sets we select. 
To this end, a non-trivial part of the construction process involves manual curation 
of the protein complexes obtained from the sources. 


%%FIXME: for some of these evidence codes we remove the predicted
%%complexes because they are based on data that we will later perform
%%our own modeling. I am not sure whether they should be included in
%%the ScISIverified or not?

%%I don't think so, it has yet to be validated...it is the investigator's
%%estimate


%%FIXME: I would like to say that they tend to be too big - in that
%%they include proteins that we would not use - maybe we need to give
%%some specific examples - RNA Pol I, II and III? By being too big we
%%then have some problems down the road, as estimates from apComplex
%%will appear to be subcomplexes and get removed.

\subsubsection{AP-MS Experimental Data}

Although we have excluded the high through-put AP-MS protein complex
estimates from the MIPs repository, we do not reject them universally.
We obtained the reported bait to prey results from three high through-put 
AP-MS experiments \citep{Ho, Gavin, Krogan}. These data-sets were then 
assembled and processed using the technologies reported in 
\citep{Scholtens, ScholtensVidalGent}, in particular using the software
packages \Rpackage{apComplex} available from the Bioconductor project.



%%FIXME: Denise, can you add a descriptive paragraph or two.

The output of the analysis are putative protein complexes. They come
in several different varieties, and we make use exclusively of the
multi-bait multi-hit (MBMH) complex estimates.

In using \Rpackage{apComplex} to process the raw, unfiltered AP-MS
experimental data, we streamline the estimation process so that 
high through-put annotated protein complexes depends on a single, 
unique methodology. This uniformity is beneficial in many ways. 
It allows for analysis on the putative protein complexes without 
the use of other statistical mechanisms such as boot-strapping 
adjustments. The technology of \Rpackage{apComplex} allows the 
end user to adjust the levels of sensativity and of specificity, so
that different users can generate different estimates based on 
various error models. Lastly, the statistical model by which 
\Rpackage{apComplex} processes the data gives a sound
and robust mechanism to manage experimental errors (both false
positive and false negative observations). 

The putative estimates resulting from the \Rpackage{apComplex} 
processing has shown to be more consistent with known biology. 
\citep{Scholtens, ScholtensVidalGent} have shown that the MBME 
putative protein complexes have significant overlap when compared
with well known protein complexes and have predicted the exact
protein composition of Arp 2/3 and of Cleavage Factor IA complexes
from the raw experimental data of \citep{Gavin}. 
In addition, the size distribution of these MBME complexes 
corresponds more with the distribution of the size of known 
complexes indicating that these estimates have a better mechanism
to filter out false postive protein complex affiliations.

The raw experimental data from \citep{Ho, Gavin, Krogan} have 
already been processed, and each MBMH estimates are stored as 
an bi-partite graph incidence matrix within the R package 
\Rpackage{apComplex}. \Rpackage{apComplex} also uses systematic
gene names to annotate proteins for complex membership, so that
the incidence matrices stored within the package also have the
rows indexed by these systematic gene names. Because 
\Rpackage{apComplex} generates the putative protein complexes
each time data is processed, it does not generate any meaningful
names for each complex. Rather, \Rpackage{ScISI} creates an 
ad hoc name for each protein complex based on the experiment by
which the complex is derived.

Having obtained the protein complex estimates from 
\Rpackage{apComplex}, we proceed to the actual construction
of the protein complex interactome.



\subsubsection{Merging of the Data-Sets}

%Table~\ref{ta:Repetitions} reports the number of protein complexes 
%that were redundant by comparing the repositories
%pairwise including self comparisons. Table~\ref{ta:Repetitions} shows 
%that the only data-set with self-redundancy is derived from the 
%MIPS repository; and upon investigation, MIPS has categorized protein
%complexes by known functionality, and three protein complexes were 
%placed in two different categories each. Table~\ref{ta:Repetitions} 
%directly shows that the no two repositories has extremely large 
%overlap.

<<testStuff, echo=FALSE, results=hide>>=

#data("redundantM")
#data("subCompM")
@ 


<<redundant, eval = TRUE, echo=FALSE, results=tex >>=


#xtable(redundantM, display = c("s","d","d","d","d","d"), label =
#"ta:Repetitions", caption="Number of repetitive Protein Complexes") 

@ 

%Not limited to redundant protein complexes, we also process each
%data-set independently to find and to remove all protein
%sub-complexes. The results are reported in Table~\ref{ta:subComplexes}
%where the row names indicate the location of the sub-complex and the
%column names indicate the location of the aggregate protein complex.
%Reading across row two of Table~\ref{ta:subComplexes} we see that GO
%contains protein complexes that were protein sub-complexes in each of
%the other data repositories including
%itself. Table~\ref{ta:subComplexes} is much less sparse relative to
%Table~\ref{ta:Repetitions}, and it is this relative comparison that
%makes all the estimates more credible since each data repository is
%based on unique experiments coupled with unique estimation algorithms.

<<redundant, eval = TRUE, echo=FALSE, results=tex>>=

#xtable(subCompM, display = c("s","d","d","d","d","d"), label =
#"ta:subComplexes", caption = "Number of Protein Sub-Complexes") 
@ 

After we have obtained the protein complex membership data-sets and 
transformed each of them into the incidence matrix representation, we 
proceed with constructing an aggregate protein complex interactome
by combining the different incidence matrices into one single 
non-redundant bi-partite graph incidence matrix. The process of merging
the smaller incidence matrices is non-trivial, for we need to 
analyze and compare each individual protein complex with all other
protein complexes. Before we proceed, we prove a small lemma that will
help simplify the merging process.


\begin{Lem}
Let $C_1,\ldots,C_n$ be non-trivial finite sets which need not be
disjoint. Comparing all the sets $(C_1,\ldots,C_n)$ and removing all 
sets $C_{l_m}$ properly contained in any $C_i$ $\forall i \in [1,n]$
is an associative process, so it can be reduced to pairwise comparisons 
in any order.
\end{Lem}

\begin{proof}
  The proof of the lemma is a clear application to the fact that set 
  inclusion is a transitive property. For instance, suppose we have
  three sets $\{C_i, C_j, C_k\}$. We may assume that $C_j \subseteqq C_i$ 
  for otherwise, we do not delete $C_j$. If we first compare $C_j$ 
  with $C_i$, we would immediately delete $C_j$ when we see the proper
  inclusion. Now we can also suppose that $C_k \subseteqq C_j$. Then 
  we must have $C_k \subseteqq C_i$, and so it still be removed. 
  We have shown comparisons to be independent of ordering and therefore,
  is an associative process.
\end{proof}

With the an application to the lemma, we can merge each bi-partite
graph incidence matrix iteratively by combining these matrices
pairwise. As an example, we detail how the proein complexes of GO,
$I_{GO}$, and of MIPS, $I_{MIPS}$, are merged.

We define the merging of two interactomes as not only combining the
protein complexes from $I_{GO}$ to $I_{MIPS}$, but also removing
protein complexes which are common to both interactomes. With such 
a merging process, each protein complex needs to be compared with
all other complexes to avoid redundancy. We note that we have not
used the lemma to its full strength, i.e. we can also remove a
protein complex of $I_{GO}$ which is sub-complex to a complex of 
$I_{MIPS}$ (or vice versa), and the process would still be 
independent of ordering. A different interactome can be estimated
in such a merging process, but we have not elected to create such
an estimate.
 
Once the matrices $I_{GO}$ and $I_{MIPS}$ are merged into $I_{GM}$,
say, we can repeat the process described above by merging $I_{GM}$ with
another incidence matrix. This process is repeated until all estimates are
merged. We will refer to the resulting aggregate interactome as
$I_c$. %%FIXME: is it worth pointing out/proving that order does not matter?

%%The stuff written below does not seem to fit in the methods section,
%%but more in a discussion section??? Seems like the intro to a dynamic
%%algorithm paper or something???

%When estimates of the interactome are available from different sources
%we must devise a method for combining them to provide a larger and
%more general estimate. How we do this depends a bit on the estimates
%themselves. We leave to another time a discussion of how to address
%issues of systematic and stochastic errors and rather consider the
%problem of having two different estimates of an interactome that we
%want to combine into a non-redundant joint estimate. The two different
%estimates may come from different sources and hence could overlap by a
%little or a lot. 

%The so-called \textit{alignment} problem arises because some
%complexes might not be labeled or are  unambiguously identified. The genes (or
%proteins) that make them up, are well identified but the collections
%are not. So, one of the first steps is to identify redundancy and to
%eliminate it. For simplicity we presume that the complexes in one
%estimate are labeled $C_1, \ldots, C_k$ and in the other
%$K_1,\ldots,K_l$, where $k$ and $l$ are generally not the same.
%We will discuss set theoretic relationships between the $C_i$ and
%$K_j$ in terms of the proteins that constitute the complexes. Thus,
%the statement, $C_i = K_j$, means that all proteins in $C_i$ are in
%$K_j$ and the converse also holds. The statement, $C_i \subset K_j$
%indicates that $C_i$ is a proper subset of $K_j$, that is, they are
%not equal.

%%FIXME: could we look at the intersection of their respective PPI
%%graphs as a measure of concordance?

%Complete concordance occurs when $C_i = K_j$, such complexes are
%reasonably easy to identify and only one of them is retained. A
%somewhat more difficult case is when $C_i \subset K_j$. For some
%technologies we will retain $C_i$ and for others we want to retain
%$K_j$. The user will have to specify which of the two alternatives
%they want. Both cannot be retained due to identifiability
%problems. %%FIXME: is this true - and do you have an example etc?

%Since much of the data is derived from experimentation and the
%underlying experiments tend to have high error rates (FIXME:citations
%etc here) some consideration of near concordance must also be
%considered. 

%What measures will we use? What graphics/summary statistics can be produced?

\subsection{Binary Interaction Interactome}

Now we consider the problem of creating the protein binary interactome, $I_b$.
Again, our basic strategy is to assemble the available experimental results
with the use of relevant software tools. Unlike the construction of $I_c$ where
the data is collected from five disparate sources, we restrict ourselves to 
the single data repository \texttt{IntAct}. There is a high level
of redundancy across different databases with respect to direct protein-protein
interaction data, so collecting data from the various repositories does not 
offer substantially more interaction data that can be harvested exclusively from
the \texttt{IntAct} database. 

%[FIXME - is the following what needs to be said?]

The protein binary interaction data is almost exclusively based on yeast 2-hybrid
experimental data, and as a result, we have imposed extra structure to the 
protein binary interactome by requiring it to contain the bait to prey relationship
derived from the Y2H experiments. Imposition of this condition translates 
the undirected protein-protein interaction graph to a directed bait to
prey interaction graph. This relationship is still binary though non-symmetric, 
and this will be the model
by which we will base $I_b$. This additional structure produces an interactome that
more accurately reflects the current state of biological knowledge, since the 
majority of protein-protein interaction has yet to be tested in a symmetric manner.

<<getGraph2, echo=FALSE, results = hide>>=
data(eAt)
pdf("arp23Y2HG2.pdf")
plot(arp23G, "dot", edgeAttrs = eAt, nodeAttrs = nAt)
dev.off()
@ 

<<getGraph3, echo = FALSE, results=hide>>=
data(eAt2)
pdf("arp23InfG.pdf")
plot(arp23G, "dot", edgeAttrs = eAt2, nodeAttrs = nAt)
dev.off()
@ 

\begin{figure} 
\centering
\subfigure[Crystal Graph of Arp 2/3 - the edges represent true protein-protein
interaction derived from crystallography.]{
\label{arp23Crystal}
\includegraphics[width = 50mm]{arp23Graph.pdf}}
\subfigure[Y2H Graph of Arp 2/3 - the directed edges represent affiliation 
from the bait proteins towards the prey proteins.]{
\label{arp23Y2HGraph}
\includegraphics[width =50mm]{arp23Y2HG2.pdf}}
\subfigure[Inferred Protein-Protein Graph of Arp 2/3 - the red edges represent 
computationally inferred interactions.]{
\label{arp23InfGraph}
\includegraphics[width =50mm]{arp23InfG.pdf}}
\caption{These figures show the  difference between the true atomic structure 
determined by crystallography and by Y2H experimentation as well as crystallography
and computationally inferred interactions. The missing edges from the Y2H graph is 
indeterminate since missing edges can either be due to un-testing or due to false 
negative observations.}
\end{figure}


A fundamental difference needs to be made between the lack of edges within this 
graph. An edge is missing between two proteins $p_1$ and $p_2$ in $I_b$ if either
$p_1$ never interacts with $p_2$ (a true negative interaction) or $p_1$ has never 
been tested with resect to $p_2$ (an untested interaction). Problems arise in the 
structure $I_b$ because neither the bait population nor the prey population is ever 
fully documented. In this way, the distinction between true negative edges and
untested edges becomes indeterminate. We detail some methods to overcome this
problem in the following sections.

Our choice to keep the bait to prey association is also subjective, and we note 
that different investigators are likely to make different choices as the nature 
of this interaction graph. 

\subsubsection{Obtaining Binary Interaction Information from the IntAct Repository}

In beginning the construction of the protein binary interactome, we again parsed 
for specific key terms. Looking in the molecular interaction (MI) category of the
Proteomics Standards Initiative (PSI) (cite PSI), we searched for the three
related character strings:

\begin{enumerate}
\item y2h;
\item yeast two hybrid;
\item 2-hybrid.
\end{enumerate}

Of the return values from this textual search, we made use of four MI identification 
codes:

\begin{table}[hb]
\centering
\label{MI Codes}
\begin{tabular}{|l|p{0.65\textwidth}|}
\hline
MI Code&Description\\
\hline
MI:0018&Two hybrid;\\
MI:0397&Two hybrid array;\\
MI:0398&Two hybrid pooling approach;\\
MI:0399&Two hybrid fragment pooling approach.\\
\hline
\end{tabular}
\caption{The MI codes corresponds to the type of experimentation conducted.}

\end{table}

We can use these MI codes to parse one sub-directory of the IntAct repository 
accounting for the various wet-lab experiment information. We found fourty-one
Intact Acension Codes (AC) whose interaction dectection slots
contained one of the four MI codes. The fourty-one IntAct AC's represented the
various wet-lab experiments conducted using the yeast 2-hybrid techonology or 
some derivation thereof. 

For each 2-hybrid experiment, we first generated a list of the proteins 
hybridized with a binding domain (these constitute the bait proteins), and 
for each of these bait proteins, we generated a list of proteins hybridized
with an activation domain (the prey proteins) found to experimentally 
interact with the respective bait protein. In essence, we have created 
one representation of the bait to prey binary interaction graph.

\subsubsection{Merging the Yeast 2-Hybrid Experimental Data}

Before we merge the various bait to prey association lists, we need to restrict
the experiments we allow into the protein binary interactome. In combining the 
various experimental data, we would like only to merge those data-sets which have
similar experimental structures so that statistical model on which we have 
based the interactome is relatively independent for the sampling of bait proteins
as well as identically distributed. With these structures in mind, we have set a 
lower bound for the number of non-trivial interacting baits at the threshold of 
twenty proteins. In addition, we have imposed the condition that the set of 
potential prey population must be genome wide. 

While it is problematic to assure that the latter of these two conidtions is 
true, the addtion of this particular structure allows for a more meaningful
dialog of $I_b$. This is so because the vertex set of $I_b$ will be genome 
wide, and testing bait proteins implies generating the induced directed 
sub-graph from the sampled baits against the genome. This genome-prey condition
also reduces the un-tested edges to prey only proteins (i.e. those
proteins never sampled and selected as baits) for otherwise, un-tested edges 
could exist between bait proteins and non-prey proteins. 

With these two conditions, we have restricted the number of viable Y2H 
experiments to a total of eight. From these eight experiments, we can create
the adjacency matrix representation of the binary protein interaction 
graph, $I_b$. 


\section{The estimates}

%%FIXME: these numbers should be computed from the package, not given

   
\section{Validation}

There are a number of different methods that can be used to validate
the ScISI prediction. Our basic premise is that the complex is a
collection of physically connected proteins. While, in some cases this
may not be strictly true and there could be two or more subcomponents
that do not physically interact we will demonstrate that such cases
have little impact on the validation methods we employ and hence are,
to a large extent, covered by our proposals.

If all physical interactions between proteins were known, then the
problem would be somewhat straightforward to address. One would simply
take a predicted complex and determine whether the constituent
elements interact and deem the complex \textit{viable} if it could be
configured as a single connected component. However, very few
interactions are known, and it is this incompleteness that requires us
to make inference about whether the prediction is likely to be
valid. Unfortunately the topology of the complexes (the set of actual
true interactions) is unknown and hence cannot itself be used to
assess the observed data. We do not know how many edges (physical
interactions) there should be, and whether the complex follows a spoke
topology, a matrix topology or any of the many other
possibilities. 

We also note that one of the alternatives that some have used, which
is to compare their predictions to the published, and to some extent
verified complexes described in GO and MIPS is not available to us. We
used those sources in construction of our estimate and hence cannot
validate against them. Instead we make use of two other sources of
data. One being the set of observed yeast two-hybrid (Y2H) experiments
available from IntAct and the other being a set of predicted
protein-protein interactions from \cite{PPIpred}.

Before describing the data we briefly discuss the statistical issues
involved. In most cases only a subset of the genes were assayed, or
considered and it will be important to restrict the computations to 

A working hypothesis is that every protein complex is a single
connected component, so that when the complex is functional it is a
single unit. This does not mean that every protein physically
interacts with every other protein, in some cases a protein may
interact with only one other protein, while in other cases it may
interact with many. %%FIXME: Tony we need some pictures, we should
                    %%have some small number of proteins with labeled
                    %%edges so we can refer to them in the text.

\subsection{Y2H Validation}

%%FIXME: Tony, please report here 1) number of experiments, that we
%%are dropping those with less than 20 interactions since there is
%%likely to be substantial experiment to experiment variability.
%% Maybe a table with experiments, system (Gal4), number of baits
%% and whether it is genome wide.

We rely on Y2H data provided by IntAct (citation) and compute a number
of summary statistics for the complex estimates in the ScISI. We
obtained data on 41 Y2H experiments comprising 1980 unique reported bait 
proteins and 3073 unique reported prey proteins. It is important to 
recognize the fact that information can
only be obtained for complex estimates that contain one or more Y2H
bait proteins. And since the actually physical interactions are not
known, the topology of the Y2H graph is also not known.
%%FIXME: Tony describe the number of experiments here, a table
%%describing something about baits into

Any bait protein in a Y2H experiment should find one or more complex
co-members provided those co-members were available as prey in the Y2H
experiment. This proviso indicates one of the true weaknesses of Y2H
data as they are often reported since only information about the prey
that were detected and not the prey that were tested is
reported. Thus, the absence of an edge is not as informative as it
could be. We do not know if it was tested and not found or not tested,
and these are very different things.


\subsection{PPI Predictions}

<<ppipred, echo=FALSE, results=hide>>=
library("y2hStat")
data(ppipred)
@ 

\cite{PPIpred} report \Sexpr{nrow(ppipred)} pairwise predictions
between proteins in \textit{S. cerevisiae}, with a presumed 
false positive rate of $3E-4$ and a presumed false negative rate of
$0.85$. The predictions are accompanied by a probability and one can
select only those predicted interactions according to this
probability. We have chosen to use only those interactions where the
probability is at least $0.5$. This greatly reduces the number of 
predicted interactions and also greatly reduces the number of
proteins that were observed. 

When using these data, only proteins that are predicted to be involved
in at least one interaction are \textit{observable}. This changes as
the probability cut-off changes and can be interpreted as the
sensitivity of the analysis. This phenomenon is no different than that
observed with different experimental procedures, not all interactions can
be detected with all procedures and one must make some efforts to determine
which interactions can be detected.

Once the observable proteins have been determined they can be use to
compute the different summary statistics discussed in
Section~\ref{sec:summary}. 

For each protein complex, $C$, we divide its constituent proteins into two
sets, those that are observable, denoted $U$ and those that are not,
$\overline{U} = C \\ U$. If $P \in U$, then we expect there to be 
an edge between $P$ and some other member of $C$, but we will only
observe this edge if it is to another member of $U$. 


\subsection{Summary Statistics}
\label{sec:summary}

As stated above, our definition of a multiprotein complex presumes
that every member is physically linked to at least one other member of
the complex. Stated in graph theoretic terms we assume that the graph
of a complex where nodes represent proteins and edges represent
physical interactions is connected. 

To develop appropriate statistical methods we describe the same
setting in a slightly more abstract notation. For a given complex,
$C$, say, consisting of $n$ proteins the graph that represents this
complex must be connected, by our definition of a complex. Hence,
there are between $n-1$ and $n(n-1)/2$ edges. We can conceptualize
this in the following way. Consider an urn that contains balls, each
ball represents on possible edge, or binary interaction. For $C$ there
are $n(n-1)/2$ possible edges and hence there are that many balls in the
urn. Some of the balls represent edges that truly exist in $C$, and these
are colored black, the remainder of the balls are white.

We will, in some cases, use the notation $G_C = (V_C, E_C)$, to denote
the graph induced by $C$. We note that in this graph the edges are not
directed and there are no self-loops. That is, we assume that no
protein in $C$ has an edge to itself, in part this makes the math
simpler and in part it reflects the technology. While AP-MS can
determine the constituent elements of complex it cannot directly
ascertain their multiplicity.

The first problem we address is estimating the number of black balls
in the urn. We label this unknown quantity $X$. The basis for this
estimation is the sampling of some nodes of $C$ and determining which
other members of $C$ they are observed to be connected to. We will
presume that the nodes that are sampled are a simple random sample
from the population $V_C$, but note that this is not always the case
in real experiments. Let $k$ denote the number of nodes sampled and
let $n= |V_C|$, when needed we will also use $n_C$. Further, let $x$
denote the number of distinct edges found based on the sampling of $k$
nodes. 

To determine how many edges were tested we note that the first node is
compared to the remaining $n-1$, the second to the remaining $n-2$ and
so on. So, the number of edges tested is $[(n-1)+(n-2)+\ldots+(n-k)]$.
If we sample all nodes then the sequence is, 
\[
\sum_{j=1}^{n-1} (n-j) = \sum_{j=1}^{n-1} j = \frac{(n-1)n}{2},
\]
where we have made use of the well known relationship regarding the sum
of the first $n$ integers. And hence, sampling all nodes does in fact
result in the inspection of all edges.

A widely used estimate of $X$ arises from equating the observed
proportion of edges in the sample, with the unknown proportion in the
population. That is,
\begin{eqnarray*}
\frac{\hat{X}}{n(n-1)/2} & = & \frac{x}{[(n-1)+(n-2)+\ldots+(n-k)]} \\
\hat{X} & = & \frac{ x (n)(n-1)}{2 [(n-1)+(n-2)+\ldots+(n-k)]} \\
\end{eqnarray*}

A second estimator can be derived from the following argument. If the
nodes that are sampled represent a random sample from the population
of nodes, $V_C$, then the observed mean degree is an unbiased estimate
of the population mean degree. The population mean degree times $n$
divided by 2 is an estimate of the number of edges. For each sampled
node we let $d_i$ denote its observed degree. So, we have
\[
\tilde{X} = \frac{ n \sum_{i=1}^k d_i}{2k}.
\]

The two estimators are quite similar, and sometimes identical.

At this point we have merely estimated the number of edges in $G_C$,
from that we make the next step of assessing whether or not $G_C$ is
connected. There are a number of factors that influence that
determination and we provide simulation examples and evidence of how
these different factors can be used.

First, the larger $X$ the more likely the graph is connected. Next, we
can examine the number of unique nodes that were selected either as
part of the $k$ nodes used to probe the graph or as the other ends of
the detected edges. The more nodes detected this way, the higher the
probability that the graph is connected. And finally, we can take the
observed subgraph, induced by our sampling, and determine how many
more edges are needed to obtain a connected graph; the fewer the more
likely it is that the true graph is connected.

We also explore a simulation approach to assessing whether the
underlying graph is connected. Given the observed edges for the $k$
query nodes and the estimated number of edges in the graph, $X$, one
can simulate the remainder of the graph by drawing from the remaining
edges. For each sample, one can assess whether the graph is
connected. Repeating this a large number of times yields some number
of connected graphs and some number of unconnected graphs. The
relative proportions can be used to assign a probability that the
underlying graph is connected. This approach can also be loosened if
desired and other measures made on the simulated graphs.

% If the graph is connected there must be at least $n-1$ black balls,
% but simply having $n-1$ black balls will not ensure that the graph is
% connected. However, the more black balls there are, the more likely it
% is that the graph is connected. We use this observation as the basis
% for our proposals. We let $X$ represent the true number of black balls
% in the urn and note that this number is unknown and hence needs to be
% estimated.
%%FIXME: note that if we associate a pair of names with each ball then
%%the graph is connected when the union of those names is of size n,
%%but it is not obvious to me how we might use that.

% Both sampling schemes, Y2H and PPI predictions, can be viewed as
% drawing some number of balls from the urn. For each ball drawn we do
% know if that ball represents a true edge (and hence is black) or not,
% provided we are willing to presume that there are no false positives
% and no false negatives. Thus the observed data can be interpreted as
% having $k$ black balls among $l$ draws. A simple estimate of $X$ can
% then be found by equating the proportion of black balls in the sample
% with the proportion of black balls in the population. And hence that, 
% \[
% \hat{X} = \frac{k n (n-1)}{l},
% \]
% and one can also easily show that $E(k n(n-1) / l) = X$, under a
% random sampling scheme and that
% $var(k n(n-1)/l ) = X(n(n-1) - X) (n(n-1) - l) / [l (n(n-1) - 1)]$,
% although one suspects that better estimates can be obtained.

% A potentially better idea is to use the fact that for some types of sampling,
% especially that of Y2H, the observed out-degree is an unbiased
% estimate of the true outdegree. That, times the number of nodes/genes
% in the complex gives an estimate of the number of edges, which has
% the advantage of being unbiased. One suspects that better estimates
% of the number of edges could be acheived by using in-degree as well,
% but those estimates are biased.

Once we address real experimental data, the situation changes and
becomes more problematic. Some alternative approaches will be needed. 
In addition we propose four different summary statistics and
investigate their behavior using the ScISI and the available Y2H data.

\begin{enumerate}
\item For a given protein complex, $C_i$, find all complex members,
  $P_j$ that were used as a bait in some Y2H experiment. For these,
  compute the proportion that found at least one other member of the
  complex. If $P_j$ was used as a bait in more than one Y2H experiment
  do not double count, but take any positive result as positive.
\item For a given protein complex, $C_i$, find the average out-degree
  of all bait proteins, again avoid double counting, in this case by
  taking the maximum out-degree. Divide this by the complex size.
\item Given the number of proteins in a complex that are detected as
  either bait or prey, find the number that are connected to at least
  one other complex co-member. [Should this be the proportion of
  complex members that are connected to at least one other complex
  member?] 
\item Compute the ratio of the number of edges needed to make the
  complex connected, by adding to the observed edges, divided by the
  minimum number of edges needed to create a connected graph from the
  complex. This is essentially a measure of incompleteness.
\end{enumerate}


\section{Discussion}

What did we learn,

\bibliographystyle{plainnat}
\bibliography{bioc}

\end{document}
