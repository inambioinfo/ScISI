%
% NOTE -- ONLY EDIT ScISI.Rnw!!!
%
%\VignetteIndexEntry{ScISI Working Paper}
%\VignetteDepends{}
%\VignetteKeywords{Interactome}
%\VignettePackage{ScISI}
\documentclass{article}

\usepackage{hyperref}
\usepackage{natbib}

\textwidth=6.2in
\textheight=8.5in
%\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textsf{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}



\newcommand{\classdef}[1]{%
  {\em #1}
}

\begin{document}
\title{Creating in Silico Interactomes}
\maketitle

\section{Introduction}

Understanding protein interactions (a fundamental part in the biological
machinery)
is relevant to our understanding of complex biological processes and
to deciphering the different roles played by genes and proteins. A
number of high throughput experiments have been carried out with the
goal of helping to elucidate these nature and number of their 
occurances \citep{Gavin, Ho, Krogan, Ito, Uetz, Giot}. Yet our knowledge is
very incomplete. Hence, not only do we need more experiments but we
also need fundamentally different experiments to fully reveal the
various network structures (FIXME: justify this?). Such
experiments, however,  are expensive and time consuming to carry out, suggesting
that simulation models may help to identify the viability of
experimental procedures, to aid in integrating data from disparate
sources, and to provide a sound basis for the development of new
methodology in designing experiments and in analyzing the resultant
data. In this paper we outline one approach in the creation of
\textit{in silico interactomes}.

In this paper we consider the problem of estimating an \textit{in
  silico} interactome, ISI, for \textit{Saccharomyces cerevisiae} and
we describe five different roles where such a computational device can
be used.  First, the ISI provides a tool that can be used to mimic
wet-lab experiments; these \textit{in silico} experiments can help to
confirm the viability of the wet-lab experimental procedures by
allowing investigators to alter experimental conditions (by the modification
of both stochastic and systematic error rates) and then measure how
the outputs change as the error rates do. Second, the ISI provides a
tool from which multiple data sets can be generated, under different conditions,
so that the statistical properties of different proposed estimation
procedures can be directly compared. A third use for the ISI is to use
it to help develop tools and strategies for small scale experiments
that can probe the interactome at a very detailed level. For example,
a reasonable strategy to investigate a coherent set of protein
complexes is to first select a small number of candidates and explore
their interactions, say via affinity purification (co-precipitation)
experiments. Once the first experiment has been collected one would
like to analyze the data and determine an optimal, or nearly optimal
set of baits for future experiments. A fourth use of an ISI is to
study the effect of perturbations in a network.  Such perturbations
could be caused by evolution (and hence could become part of the study
of evolutionary pressure on the interactome) or due to drug treatments
(and hence would become part of a clinical investigation into the
likely effects of drug treatments). The fifth use for such a tool is
to explore and understand the effects of different sampling paradigms
on the inferences that can drawn from different wet-lab
experiments. We note that there are a number of recent papers
\citep{Oltavi,Goverview, SubsampNetworks} that raise many important
issues in this regard.

An ISI is not without its limitiations. It cannot reveal new
relationships between its members, but rather can only reflect the
current state of biological knowledge. It can, however,  be used out 
in any of the
five tasks listed above. Further, one type of interaction can
be used either to predict or to model other types of interactions, and
provide information about the likelihood of interactions; the
verification of interactions remains the domain of experimental
biology. 
%%FIXME: this needs a bit more
We are aware of the very dynamic nature of protein interactions and
that different interactions occur at different times and under
different conditions. We provide some tools that will allow
investigators the ability to indicate situations and conditions under
which an interaction is known to occur and we discuss a paradigm where
an investigator will be able to select all interactions for a given
condition. Our example is based on \textit{S. cerevisiae}.
%%FIXME: we are going to need a separate table that maps protein
%%complexes to conditions. Then users could ask for the complexes that
%%are active under condition X.

While the estimated interactome is itself of some great interest, we
note that it is more important to describe the procedure by which an
ISI is produced. There are many reasons why the estimate is of less
importance, among them the fact that the methodology can be applied to
many organisms and tissue types to yield specialized ISI estimates. We
also note that the data used in the construction is constantly being
updated and improved, hence users will want to regularly update any
estimate as new data sources become availble, or old ones are
updated. Hence, there to be viable there must be a mechanism for
updating and refining the ISI. We also note that there are many
different and disparate data sources and the system should be
sufficiently flexible to allow users to select data sources
appropriate for their studies as well as the ability to incorporate
additional data from new and potentially different experimental
techniques. Finally we note that investigators will often want to
modify the ISI, either with locally produced, though not yet public,
data, or to satisfy personal beliefs. The paradigm we describe here
allows investigators to create their own personalized estimates, to
share interactomes and to revise and update interactomes.

In this paper we first define the notion of a biological interactome and 
give various examples of such interactomes. We then present a  
computational tool (\textit{ScISI}) 
we have built to search for and to collect protein complex membership 
data from various protein interaction repositories. Next we describe 
the primary data sources used by \textit{ScISI} in constructing the 
\textit{in silico interactome}. We then describe how those data
sources are combined to provide a comprehensive interactome that can
be used as an input for the various computational tasks described
above. Finally we report on some \textit{in silico} experiments that
can be performed using the estimated interactome.

In our discussion we do not distinguish between the term gene and the
term protein, since the available resolution is not fine enough and
equating these concepts leads to a more comprehensible dialog. The
methodology is sufficiently general to be able to address the more
complicated situation of different protein/polypeptide variants should
they arise.

\section{Biological Interactomes}

In the broadest sense, an interactome is a set of elements $P$, for
our purposes $P$ is the set of genes (or their related proteins)
within a particular organism or cell type. The elements of $P$ have
a variety relationships with each other and each of these different
relationships can be modeled using some form of graph. Some
relationships are binary, for example, protein $p_1$ is known to
directly physically interact with some other protein, $p_2$. In other
cases, the relations are not binary but rather are one to many or many
to many. The example we use for this second type of relationship is
that of protein complex membership. In this setting all members of
a complex are related to each other, but they need not directly
interact and the relationship is not binary. A reasonable model for
such data is as either a hypergraph \cite{Berge} or, equivalently,
the bipartite graph representation. Proteins are grouped into sets
according to whether they are in a complex and these sets constitute the
hyperedges of the graph. There is no need for the hyperedges to be
disjoint and proteins can be in many or few hyperedges, depending on
whether the protein is in many or few complexes.

We begin by distinguishing between many different types of
interactomes with a few general comments, we will make the
terms and ideas more explicit in later sections of this report. There
are interactomes that model direct binary interactions and hence are
related to experiments using the yeast two hybrid (Y2H) system
\citep{Y2H, Ito, Uetz}. A second type of interactome is one that
models protein complex membership. In this model, two proteins are
said to interact if they are constituent members of some protein complex 
under the conditions of interest. This second type of interactome is
more closely related to co-precipitation or affinity-purification
experiments \citep{Ho, Gavin, Krogan}. We note that proteins which
interact in the second sense, need not interact in the first sense;
hence, we separate these two different, but related, concepts. Other
interactomes can be created by considering other relationships such as
those between transcription factors and their direct targets or the
interaction network that can be defined on pairs of synthetically
lethal genes \citep{Tong2004}.

% We can relate the two previous population interactomes to biological
% interactomes. Now let $P$ be the set of genes within the genome of some cell
% or tissue. Let $Y$ be the interactome on the set $P$ where the association
% is direct binary interactions between genes, i.e. two genes $g_1$ and $g_2$
% are said to be associated if and only if the induced protein of $g_1$ and the 
% induced protein of $g_2$ directly interact for some bio-physical or bio-chemical 
% process. We remark that a gene may be associated with itself if it induces a 
% homo-dimer. Next, let $A$ be the interactome on the set $P$ where the association is
% protein complex co-membership, i.e. two genes $g_3$ and $g_4$ are associated
% if and only if their respective induced proteins form constituent parts to
% some protein complex that has some biological objective. 

These two biological interactomes are related, but they are also
distinct, and the use of the data in modeling and other downstream
uses requires that some caution be used to not confuse the
concepts. It is certainly the case that for our working definition of
a protein complex the members of that complex will have some binary
interactions with other members. But not all members have direct
physical interactions with other members, so we would not use a
so-called \textit{matrix} model \cite{FIXME:matrixmodelcitation} to
represent those interactions. These two examples highlight the subtle
differences between two distinct interactomes and underscores the
necessity to keeping distinct interactomes separate. We will refer to
the first of these interactomes as $I_b$, where the $b$ subscript
reinforces the notion that binary relationships are being modeled and
the second as $I_c$ where the $c$ subscript reinforces the notion that
protein complexes are being modeled.

There are of course many limitations to such an approach, however,
there will be ample opportunity to refine and revise the models
proposed here as our knowledge of the underlying biology improves and
as the available computer technology improves. Among the limitations
is the observation that some interactions will only take place under a
specific set of conditions, and that other interactions, sometimes
involving the same proteins, will occur under other conditions. Thus,
the model representing these data will need to become richer and to be
able to indicate under which conditions a given relationship is known
to occur. Some interactions are specific to certain tissues (in higher
organisms) or to particular phases of the cell cycle, and so on. The
models we propose can be extended in fairly straightforward ways to
encompass these details, but the available data are currently to
sparse to warrant such an approach. We will note some experiments, and
some uses of existing experimental data, that can provide some
insight. 

In this paper, we will report on a set of methodological tools that
can be used to construct an \textit{in silico interactome}
for \textit{S. cerevisiae}. We restrict our attention to the two
interactomes described above, $I_b$ and $I_c$.


%of environmental conditions. The elements of $I$
%are the disjoint union of two sets: the first is the set $P$ of genes
%within the genome of a yeast cell; the second is the set $C$ of all protein
%complexes of yeast for a specific cell type. Association is defined as
%protein complex membership, i.e. gene $g$ is associated with protein
%complex $c$ if and only if the induced protein of $g$ is a constituent
%member of $c$. This definition implies that elements of $P$ are only 
%associated with elements of $C$ and conversely, but no element can 
%be associated with other elements of the same type. 

\section{Materials and Methods}

In this section we first describe what we mean by a protein complex
and describe different models for representing these data. Next we
give a concise description of the computational tool \textit{ScISI}
and show its dynamic properties in constructing different complex
membership interactomes. We then describe the process of creating an
\textit{in silico} interactome via \textit{ScISI} based on two public
meta-data sources and three experimental data sets by combining
purification of protein complexes with identification of their
individual components via mass spectroscopy.


\subsection{Protein complexes and their representations}

%%FIXME: a few pictures would surely help readers
We define a protein complex to be two or more proteins that physically
interact for the purposes of carrying out some biological
objective. There is no need for all members of a complex to physically
interact with each one another, but all the proteins do need to
combine to form a connected multi-protein structure. Some proteins
will be involved in many complexes while others will be involved in
relatively few. Protein complexes range in size from two proteins to
more than fifty.

%%I don't see how this helps us, we would use this if we could, we are
%%not limited in anyway by the technology, we want all the complexes.

% This definition of a protein complex is motivated by the various 
% technologies that assay levels of protein complex composition such 
% as Affinity Purification - Mass Spectroscopy and 
% Co-immunoprecipitation. It is important to note that these 
% technologies only assay protein complex composition of cells
% given a pre-described environment. Working within the confines of these 
% technologies, our definition for protein complexes becomes 
% increasingly strict. There are structures within the cytoskeleton,
% for instance, which fit within a more generic setting of a complex; 
% these structures are never pulled down by the mentioned 
% technologies, so we have dis-allowed their membership as a protein
% complex. 

There are sure to be situations where a protein complex, that exists
under one set of conditions, is a proper subset of a complex that
exists under another set of conditions. Such situations, however, will
cause some mathematical problems and for the purposes of this
presentation we remove all subcomplexes that are proper subsets of
other complexes from our estimated interactome. The appropriate
modeling of these can be handled by attaching attributes to the
complexes and then selecting those complexes with the correct set of
attributes for the conditions from which we are going to simulate.

% a complex that is entirely contained within another protein
% complex. We remark that a protein sub-complex under certain cell
% conditions could be a proper complex in other cell conditions. We
% define the convention that all sub-complexes will be masked by their
% respective proper protein complexes, and therefore, are not
% recorded. Thus our definition of protein complex is implicitly
% directed by the biological state of some particular cell or tissue,
% i.e. a complex can only be determined along with the context of the
% cell type.

%What should be said about sub-complexes? When sub-complexes exist
%there can be identifiability problems that arise due to the technology
%being used. FIXME: it would be good to give some sort of concrete
%example of what might go wrong. (Also, some protein complexes might
%be a sub-complex given other conditions...where should we draw the 
%line between when a complex is actually a sub-complex or not??? TC) 

%The collection of proteins and protein complexes with affiliation data
%can be represented as a large membership network or graph. We have
%chosen to represent the protein complex membership graph as a
%bipartite graph, $B$. The proteins themselves index one set of nodes
%which we denote as $P$ while the protein complexes index the other set
%of nodes which we denote as $C$. A protein specific node $p_i$ is
%incident to a protein complex specific node $c_j$ if $p_i$ has
%membership in $c_j$. We remark that there is an equivalence between
%the categories of bipartite graphs and the categories of hyper-graphs
%(cite or supplementary).

\subsection{Graphs and Hypergraphs}

We require a small amount of graph theory to allow for succinct
discussion of the relevant concepts. A graph $G$, consists of a pair
of sets; the vertices, or nodes, $V$, and the edges, or relations,
$E$. We write $G=(V,E)$. Graphs can be used to represent binary
relationships and hence are an appropriate model and data structure
for $I_b$. They cannot represent the more complicated situation of
modeling protein complex co-membership. In this case we require the
use of hypergraphs \cite{Berge}. A hypergraph, $H$, consists of a set
of nodes, $V$, and a set of hyperedges. A hyperedge is any subset of
$V$. Thus, for modeling protein interaction data the vertex set is the
set of proteins in the organism or tissue under study. To represent binary
relationships we will use a graph, where the edges indicate the
presence of a binary interaction and for complex co-membership data we
will use a hypergraph, where the hyperedges are the identities of the
proteins that constitute the complex. There is a one-to-one
relationship between hypergraphs and bipartite graphs and in some
reports bipartite graphs are used.

There are a variety of different representations for both graphs and
hypergraphs. We will mainly make use of the incidence matrix
representation for $H$ and the adjacency matrix representation of $G$.
For the protein complex hypergraph the
incidence matrix representation, $M_B$, is a $\{0,1\}$-matrix where
proteins index the rows and protein complexes index the columns. The
$(i,j)$ entry for $M_B$ is one if protein $p_i$ is a constituent
member of complex $c_j$; the entry is zero otherwise. When studying
binary interactions the representation will be of a graph, and then
the adjacency matrix is typically square (or upper triangular) with
the proteins indexing both the rows and the columns. In this matrix a
one in position $(i,j)$ indicates that protein $p_i$ interacts with
protein $p_j$. This matrix is likely to be sparse and we will make use
of appropriate software tools and data representations.

The construction of the \textit{in silico} interactomes, $I_c$ and
$I_b$, will be the construction of appropriate matrices.


\subsection{Constructing the Interactome}

We first discuss the creation, or estimation of $I_c$. Our basic
strategy is to assemble a number of software tools, together with
available data, from databases or experimental results. We process the
data from each database or experiment separately and then sequentially
integrate the different protein complex estimates into a single
estimate. 

The choice of input data sources and the manner in which they are
processed is subjective and different investigators are likely to make
different decisions. We report the sources that we used and the
decisions made; others can easily make use of alternative or
additional sources. We make use of two rather distinct data sources,
one is the set of published and annotated protein complex data that
can be obtained from the Gene Ontology (GO), \citep{GO},
(\url{www.geneontology.org}) and the Munich Information Center for
Protein Sequences (MIPS). Additionally we will make use of protein
complex estimates from three publicly available wet-lab experiments
\citep{Ho, Gavin, Krogan}. Rather than make use of these estimates
directly, we first apply the technology of \cite{Scholtens,
  ScholtensVidalGent} since, as demonstrated in those references, the
resultant data are more consistent with known biological complexes.

With publicly released data available in a number of disparate
sources, there is a need for computational tools to parse the
data-sets and collate them into one single, non-redundant, and
meaningful database resource. To this end, we have built the R package
\Rpackage{ScISI} for the specific purpose of processing and combining
protein interaction data.

For each data repository the textual terms used to describe its
contents are searched for specific key words. We make use of regular
expressions searches and approximate matching regular expression
searches. To be concrete we make use of the R functions
\Rfunction{grep} and \Rfunction{agrep}. By default all terms that
contain one of the three expressions listed here,
\begin{enumerate}
\item  the exact word \texttt{complex};
\item one or more words that end with the suffix \texttt{ase};
\item one or more words that end with the suffix \texttt{some}.
\end{enumerate}
Users can modify the search criteria to add new terms or to remove any
of those default values listed above. Terms selected correspond to
protein complexes and these are then collected and the corresponding
incidence matrix is computed. The rows are indexed by the standard
gene names and the columns are indexed by the protein complex identification 
codes (unique to each different repository). 

We remark that the complexes documented within Gene Ontology and the Munich
Information Center for Protein Sequences are annotated by many different 
technologies such as small scale protein complex verification experiments. Many
of these protein complexes have been exhaustively verified. 

While most protein interaction repositories store protein complex data
by listing the constituent proteins for each complex, there are a
small number of repositories which store the bipartite graph incidence
graph matrix for the protein complex data. For these repositories,
we simply download these matrices.

The resultant incidence matrices are compared pairwise and
redundant complexes are removed. Optionally, any subcomplexes are also
removed at this time.

\subsection{Processing Online Repositories}

We make use of the following three regular expressions,
\verb+complex+, \verb+\\Base\\b+,
and \verb+\\Bsome\\b+ as the default regular expressions in our search. 
These can narrow the pool of return values yet include
\textit{DNA-directed Polymerase II, holoenzyme} or 
\textit{repairosome}. 
%%FIXME: Tony - I don't see how you find holoenzyme this way?  Robert...the name is ``DNA-directed Polymerase II, holoenzyme''
%%FIXME: Tony, in the para below, I don't see why we want to exclude
%%NAS, they should be fine.  Robert, Denise and I talked about what is iffy from her talks with the GO guy in Boston
Both GO and MIPS provide additional information on the curation and
provenance of the data that they report. This information comes in the
form of evidence codes, which are used by both resource, although the
codes themselves are unique to the different resources. Users can
specify a list of evidence codes and disallow those proteins whose
annotations are found in the supplied list. Within the GO
repository, we disallow those proteins annotated by the following
evidence codes: Inferred from Electronic Annotation (IEA);
Non-traceable Author Statement (NAS); No Biological Data Available
(ND); Not Recorded(NR). 
%%FIXME: I have no idea what is happening here. These numbers act exactly like the evidence codes in GO
%%This is how the proteins were annotated to each protein complex via the MIPS evidence codes
For the MIPS repository, we restrict the
following: Overview Information - review and text (901.01.03,
901.01.03.01, 901.01.03.02); Personal Communication - via homepage
(web) or electronic mail (901.01.04, 901.01.04.01, 901.01.04.02), and
Closed Information - institution or private (901.01.05, 901.01.05.01,
901.01.05.02)

In addition to the MIPS evidence codes listed above, we have
dis-allowed proteins which are indexed exclusively by the following
codes:

"902.01.01.02.01.01.02" (co-immunoprecipitation, epitope tag)
"902.01.01.04.01.03" (matrix-assisted laser desorption/ionization time-of-light
mass spectrometry (MALDI TOF MS))
"902.01.09.02" (high throughput experiment)

When the function is given these three evidence codes, all high
through-put protein complexes are eliminated (Gavin, Ho, Krogan) with
the exception of one Krogan protein complex. This unique Krogan
protein complex (originally with 14 constituent proteins) has 2
proteins which are indexed by some other evidence codes in addition to
those listed above, and therefore, the function selected these two
proteins and the protein complex for which they belong in its parse
mechanism. Because we have built \Rpackage{ScISI} in a way so that
users can allow or dis-allow proteins based on evidence codes, this
small anomoly cannot be circumvented by the function itself. We shall
describe in a later section on QC for minor anomolies.


%%FIXME: the numbers in here should be part of an \Sexpr and be
%%computed from the actual data - otherwise why are we using a
%%vignette? 
We made use of the version in the Bioconductor package \Rpackage{GO}
version 1.10.0, which is version number XXX. We found 208 protein
complexes. The MIPS repository (as of 17 December 2005) yielded 141
protein complexes. The GO protein complexes include 1,213 unique
proteins while the MIPS protein complexes contains 651 unique
proteins. 

As mentioned before some of the MIPS protein complexes have been uniquely identified by
high through-put experimentation such as affinity purification - mass
spectroscopy ; we have, however, deliberately chosen not to extract
these protein complexes. %%FIXME: then we should do the same for GO? I don't know how, do you Denise?
The protein complexes were estimated by clustering
algorithms determined by the individual investigator of the high
through-put experiments, and therefore, protein complexes identified
via high through-put AP-MS technologies lack uniformity and
consistency from one experiment to the next. We have chosen one
standard algorithm to parse high through-put data and estimate protein
complex composition from the raw data by this algorithm.
%%FIXME: I would like to say that they tend to be too big - in that
%%they include proteins that we would not use - maybe we need to give
%%some specific examples - RNA Pol I, II and III? By being too big we
%%then have some problems down the road, as estimates from apComplex
%%will appear to be subcomplexes and get removed.

\subsection{APMS Experimental Data}

We additionally obtained the reported results from three high
throughput APMS experiments \citep{Ho, Gavin, Krogan}. These data were
assembled and processed using the technology reported in
\cite{Scholtens, ScholtensVidalGent}, in particular using the software
packages \Rpackage{apComplex} available from the Bioconductor project.

%%FIXME: Denise, can you add a descriptive paragraph or two.

The output of the analysis are putative protein complexes. They come
in several different varieties, and we make use exclusively of the
multi-bait multi-hit (MBMH) complex estimates. Again, these form a
hypergraph and we can obtain separate incidence matrix representations
for the three experiments.

\subsection{Analysis and Merging of the Data-Sets}

%%FIXME: what is reported?
Table~\ref{ta:Repetitions} reports ??? comparing the experiments
pairwise. details the number of repeated 
protein complexes for each pairwise repository comparison.

%%FIXME: should be generated from the data using R, ScISI and xtable.
\begin{table}[ht]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
       &GO &MIPS &Gavin &Ho &Krogan \\
\hline 
GO     &0  &33   &5      &1   &0                  \\
\hline
MIPS   &33 &3    &0      &2   &0                \\
\hline
Gavin  &5  &0    &0      &0   &1               \\
\hline
Ho     &1  &2    &0      &0   &0              \\
\hline
Krogan &0  &0    &1      &0   &0               \\
\hline

\end{tabular}
\caption{Repetitions %%FIXME: this doesn't mean much to me?
\label{ta:Repetitions}}
\end{center}
\end{table}

We process each data set independently to find and remove all protein
sub-complexes. We then compare the data sets pairwise to identify
sub-complex relationships between the different data sets.  The
results are reported in Table~\ref{ta:subComplexes} where the row
names indicate the location of the sub-complex and the
column names indicate the location of the including protein complex.
Reading across row one of Table~\ref{ta:subComplexes} we see that
there were 14 complexes in the GO estimate that were subcomplexes of
other GO complexes, and seven complexes in GO that are subcomplexes of
complexes in the Krogan data. 

\begin{table}[ht]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
       &GO &MIPS &Gavin &Ho &Krogan \\
\hline 
GO     &14  &27   &19   &1   &7                  \\
\hline
MIPS   &44  &16   &17   &0   &0                \\
\hline
Gavin  &25  &9    &0    &5   &0               \\
\hline
Ho     &14  &10   &9    &0   &1              \\
\hline
Krogan &8   &8    &14   &4   &0               \\
\hline

\end{tabular}
\caption{Sub-Complexes
\label{ta:subComplexes}}
\end{center}
\end{table}

  
Merging the multiple sub-interactomes into one is done 
iteratively by combining the estimates pairwise.

Let $I_{GO}$ and $I_{MIPS}$ be two estimates that we wish to merge. We
define the merging of two interactomes as not only combining the
protein complexes from $I_{GO}$ to $I_{MIPS}$, but also removing protein complexes
which are common to both interactomes. In addition to removing
redundant protein complexes, we have removed any protein complex of
$I_{GO}$ that is a sub-complex of a complex in $I_{MIPS}$ and vice versa.

Once the estimates $I_{GO}$ and $I_{MIPS}$ are merged into $I_{2}$,
say, we can repeat the process described above by merging $I_{2}$ with
another estimate. This process is repeated until all estimates are
merged. We will refer to the resultant estimated interactome as
$I_c$. %%FIXME: is it worth pointing out/proving that order does not matter?

%%The stuff written below does not seem to fit in the methods section,
%%but more in a discussion section??? Seems like the intro to a dynamic
%%algorithm paper or something???

%When estimates of the interactome are available from different sources
%we must devise a method for combining them to provide a larger and
%more general estimate. How we do this depends a bit on the estimates
%themselves. We leave to another time a discussion of how to address
%issues of systematic and stochastic errors and rather consider the
%problem of having two different estimates of an interactome that we
%want to combine into a non-redundant joint estimate. The two different
%estimates may come from different sources and hence could overlap by a
%little or a lot. 

%The so-called \textit{alignment} problem arises because some
%complexes might not be labeled or are  unambiguously identified. The genes (or
%proteins) that make them up, are well identified but the collections
%are not. So, one of the first steps is to identify redundancy and to
%eliminate it. For simplicity we presume that the complexes in one
%estimate are labeled $C_1, \ldots, C_k$ and in the other
%$K_1,\ldots,K_l$, where $k$ and $l$ are generally not the same.
%We will discuss set theoretic relationships between the $C_i$ and
%$K_j$ in terms of the proteins that constitute the complexes. Thus,
%the statement, $C_i = K_j$, means that all proteins in $C_i$ are in
%$K_j$ and the converse also holds. The statement, $C_i \subset K_j$
%indicates that $C_i$ is a proper subset of $K_j$, that is, they are
%not equal.

%%FIXME: could we look at the intersection of their respective PPI
%%graphs as a measure of concordance?

%Complete concordance occurs when $C_i = K_j$, such complexes are
%reasonably easy to identify and only one of them is retained. A
%somewhat more difficult case is when $C_i \subset K_j$. For some
%technologies we will retain $C_i$ and for others we want to retain
%$K_j$. The user will have to specify which of the two alternatives
%they want. Both cannot be retained due to identifiability
%problems. %%FIXME: is this true - and do you have an example etc?

%Since much of the data is derived from experimentation and the
%underlying experiments tend to have high error rates (FIXME:citations
%etc here) some consideration of near concordance must also be
%considered. 

%What measures will we use? What graphics/summary statistics can be produced?


\section{The estimate}

%%FIXME: these numbers should be computed from the package, not given
The result of combining data from multiple database sources is an aggregate 
protein complex membership \textit{in silico interactome}. The elements of 
this interactome consists of $1755$ proteins and $743$ protein complexes. The 
number of proteins is consistent with biological estimates (%%~40% of genome?)
of the number of expressed genes for the a particular genome;
the number of unique protein complexes gives us enough complexity to 
conduct \textit{in silico} experiments in order to emulate true wet-lab
experiments.


Histogram for the cardinalities or protein complexes?
Histogram for the order of each particular protein's complex membership?

What else should we put here???
   
\section{Validation}

There are a number of different methods that can be used to validate
the ScISI prediction. Our basic premise is that the complex is a
collection of physically connected proteins. While, in some cases this
may not be strictly true and there could be two or more subcomponents
that do not physically interact we will demonstrate that such cases
have little impact on the validation methods we employ and hence are,
to a large extent, covered by our proposals.

If all physical interactions between proteins were known, then the
problem would be somewhat straightforward to address. One would simply
take a predicted complex and determine whether the constituent
elements interact and deem the complex \textit{viable} if it could be
configured as a single connected component. However, very few
interactions are known, and it is this incompleteness that requires us
to make inference about whether the prediction is likely to be
valid. Unfortunately the topology of the complexes (the set of actual
true interactions) is unknown and hence cannot itself be used to
assess the observed data. We do not know how many edges (physical
interactions) there should be, and whether the complex follows a spoke
topology, a matrix topology or any of the many other
possibilities. 

We also note that one of the alternatives that some have used, which
is to compare their predictions to the published, and to some extent
verified complexes described in GO and MIPS is not available to us. We
used those sources in construction of our estimate and hence cannot
validate against them. Instead we make use of two other sources of
data. One being the set of observed yeast two-hybrid (Y2H) experiments
available from IntAct and the other being a set of predicted
protein-protein interactions from \cite{PPIpred}.

Before describing the data we briefly discuss the statistical issues
involved. In most cases only a subset of the genes were assayed, or
considered and it will be important to restrict the computations to 

A working hypothesis is that every protein complex is a single
connected component, so that when the complex is functional it is a
single unit. This does not mean that every protein physically
interacts with every other protein, in some cases a protein may
interact with only one other protein, while in other cases it may
interact with many. %%FIXME: Tony we need some pictures, we should
                    %%have some small number of proteins with labeled
                    %%edges so we can refer to them in the text.

\subsection{Y2H Validation}

%%FIXME: Tony, please report here 1) number of experiments, that we
%%are dropping those with less than 20 interactions since there is
%%likely to be substantial experiment to experiment variability.
%% Maybe a table with experiments, system (Gal4), number of baits
%% and whether it is genome wide.

We rely on Y2H data provided by IntAct (citation) and compute a number
of summary statistics for the complex estimates in the ScISI. We
obtained data on X Y2H experiments comprising Y baits and Z prey
protein. It is important to recognize the fact that information can
only be obtained for complex estimates that contain one or more Y2H
bait proteins. And since the actually physical interactions are not
known, the topology of the Y2H graph is also not known.
%%FIXME: Tony describe the number of experiments here, a table
%%describing something about baits into

Any bait protein in a Y2H experiment should find one or more complex
comembers provided those comembers were available as prey in the Y2H
experiment. This proviso indicates one of the true weaknesses of Y2H
data as they are often reported since only information about the prey
that were detected and not the prey that were tested is
reported. Thus, the absence of an edge is not as informative as it
could be. We do not know if it was tested and not found or not tested,
and these are very different things.


\subsection{PPI Predictions}

<<ppipred, echo=FALSE, results=hide>>=
library("y2hStat")
data(ppipred)
@ 

\cite{PPIpred} report \Sexpr{nrow(ppipred)} pairwise predictions
between proteins in \textit{S. cerevisiae}, with a presumed 
false positive rate of $3E-4$ and a presumed false negative rate of
$0.85$. The predictions are accompanied by a probability and one can
select only those predicted interactions according to this
probability. We have chosen to use only those interactions where the
probability is at least $0.5$. This greatly reduces the number of 
predicted interactions and also greatly reduces the number of
proteins that were observed. 

When using these data, only proteins that are predicted to be involved
in at least one interaction are \textit{observable}. This changes as
the probability cut-off changes and can be interpreted as the
sensitivity of the analysis. This phenomenon is no different than that
observed with different experimental procedures, not all interactions can
be detected with all procedures and one must make some efforts to determine
which interactions can be detected.

Once the observable proteins have been determined they can be use to
compute the different summary statistics discussed in
Section~\ref{sec:summary}. 

For each protein complex, $C$, we divide its constituent proteins into two
sets, those that are observable, denoted $U$ and those that are not,
$\overline{U} = C \\ U$. If $P \in U$, then we expect there to be 
an edge between $P$ and some other member of $C$, but we will only
observe this edge if it is to another member of $U$. 


\subsection{Summary Statistics}
\label{sec:summary}

As stated above, our definition of a multiprotein complex presumes
that every member is physically linked to at least one other member of
the complex. Stated in graph theoretic terms we assume that the graph
of a complex where nodes represent proteins and edges represent
physical interactions is connected. 

To develop appropriate statistical methods we describe the same
setting in a slightly more abstract notation. For a given complex,
$C$, say, consisting of $n$ proteins the graph that represents this
complex must be connected, by our definition of a complex. Hence,
there are between $n-1$ and $n(n-1)/2$ edges. We can conceptualize
this in the following way. Consider an urn that contains balls, each
ball represents on possible edge, or binary interaction. For $C$ there
are $n(n-1)/2$ possible edges and hence there are that many balls in the
urn. Some of the balls represent edges that truly exist in $C$, and these
are colored black, the remainder of the balls are white.

We will, in some cases, use the notation $G_C = (V_C, E_C)$, to denote
the graph induced by $C$. We note that in this graph the edges are not
directed and there are no self-loops. That is, we assume that no
protein in $C$ has an edge to itself, in part this makes the math
simpler and in part it reflects the technology. While AP-MS can
determine the constituent elements of complex it cannot directly
ascertain their multiplicity.

The first problem we address is estimating the number of black balls
in the urn. We label this unknown quantity $X$. The basis for this
estimation is the sampling of some nodes of $C$ and determining which
other members of $C$ they are observed to be connected to. We will
presume that the nodes that are sampled are a simple random sample
from the population $V_C$, but note that this is not always the case
in real experiments. Let $k$ denote the number of nodes sampled and
let $n= |V_C|$, when needed we will also use $n_C$. Further, let $x$
denote the number of distinct edges found based on the sampling of $k$
nodes. 

To determine how many edges were tested we note that the first node is
compared to the remaining $n-1$, the second to the remaining $n-2$ and
so on. So, the number of edges tested is $[(n-1)+(n-2)+\ldots+(n-k)]$.
If we sample all nodes then the sequence is, 
\[
\sum_{j=1}^{n-1} (n-j) = \sum_{j=1}^{n-1} j = \frac{(n-1)n}{2},
\]
where we have made use of the well known relationship regarding the sum
of the first $n$ integers. And hence, sampling all nodes does in fact
result in the inspection of all edges.

A widely used estimate of $X$ arises from equating the observed
proportion of edges in the sample, with the unknown proportion in the
population. That is,
\begin{eqnarray*}
\frac{\hat{X}}{n(n-1)/2} & = & \frac{x}{[(n-1)+(n-2)+\ldots+(n-k)]} \\
\hat{X} & = & \frac{ x (n)(n-1)}{2 [(n-1)+(n-2)+\ldots+(n-k)]} \\
\end{eqnarray*}

A second estimator can be derived from the following argument. If the
nodes that are sampled represent a random sample from the population
of nodes, $V_C$, then the observed mean degree is an unbiased estimate
of the population mean degree. The population mean degree times $n$
divided by 2 is an estimate of the number of edges. For each sampled
node we let $d_i$ denote its observed degree. So, we have
\[
\tilde{X} = \frac{ \sum_{i=1}^k d_i (n)}{2k}.
\]

The two estimators are quite similar, and sometimes identical.

At this point we have merely estimated the number of edges in $G_C$,
from that we make the next step of assessing whether or not $G_C$ is
connected. There are a number of factors that influence that
determination and we provide simulation examples and evidence of how
these different factors can be used.

First, the larger $X$ the more likely the graph is connected. Next, we
can examine the number of unique nodes that were selected either as
part of the $k$ nodes used to probe the graph or as the other ends of
the detected edges. The more nodes detected this way, the higher the
probability that the graph is connected. And finally, we can take the
observed subgraph, induced by our sampling, and determine how many
more edges are needed to obtain a connected graph; the fewer the more
likely it is that the true graph is connected.

We also explore a simulation approach to assessing whether the
underlying graph is connected. Given the observed edges for the $k$
query nodes and the estimated number of edges in the graph, $X$, one
can simulate the remainder of the graph by drawing from the remaining
edges. For each sample, one can assess whether the graph is
connected. Repeating this a large number of times yields some number
of connected graphs and some number of unconnected graphs. The
relative proportions can be used to assign a probability that the
underlying graph is connected. This approach can also be loosened if
desired and other measures made on the simulated graphs.

% If the graph is connected there must be at least $n-1$ black balls,
% but simply having $n-1$ black balls will not ensure that the graph is
% connected. However, the more black balls there are, the more likely it
% is that the graph is connected. We use this observation as the basis
% for our proposals. We let $X$ represent the true number of black balls
% in the urn and note that this number is unknown and hence needs to be
% estimated.
%%FIXME: note that if we associate a pair of names with each ball then
%%the graph is connected when the union of those names is of size n,
%%but it is not obvious to me how we might use that.

% Both sampling schemes, Y2H and PPI predictions, can be viewed as
% drawing some number of balls from the urn. For each ball drawn we do
% know if that ball represents a true edge (and hence is black) or not,
% provided we are willing to presume that there are no false positives
% and no false negatives. Thus the observed data can be interpreted as
% having $k$ black balls among $l$ draws. A simple estimate of $X$ can
% then be found by equating the proportion of black balls in the sample
% with the proportion of black balls in the population. And hence that, 
% \[
% \hat{X} = \frac{k n (n-1)}{l},
% \]
% and one can also easily show that $E(k n(n-1) / l) = X$, under a
% random sampling scheme and that
% $var(k n(n-1)/l ) = X(n(n-1) - X) (n(n-1) - l) / [l (n(n-1) - 1)]$,
% although one suspects that better estimates can be obtained.

% A potentially better idea is to use the fact that for some types of sampling,
% especially that of Y2H, the observed out-degree is an unbiased
% estimate of the true outdegree. That, times the number of nodes/genes
% in the complex gives an estimate of the number of edges, which has
% the advantage of being unbiased. One suspects that better estimates
% of the number of edges could be acheived by using in-degree as well,
% but those estimates are biased.

Once we address real experimental data, the situation changes and
becomes more problematic. Some alternative approaches will be needed. 
In addition we propose three different summary statistics and
investigate their behavior using the ScISI and the available Y2H data.

\begin{enumerate}
\item For a given protein complex, $C_i$, find all complex members,
  $P_j$ that were used as a bait in some Y2H experiment. For these,
  compute the proportion that found at least one other member of the
  complex. If $P_j$ was used as a bait in more than one Y2H experiment
  do not double count, but take any positive result as positive.
\item For a given protein complex, $C_i$, find the average out-degree
  of all bait proteins, again avoid double counting, in this case by
  taking the maximum out-degree. Divide this by the complex size.
\item Given the number of proteins in a complex that are detected as
  either bait or prey, find the number that are connected to at least
  one other complex co-member. [Should this be the proportion of
  complex members that are connected to at least one other complex
  member?] 
\item Compute the ratio of the number of edges needed to make the
  complex connected, by adding to the observed edges, divided by the
  minimum number of edges needed to create a connected graph from the
  complex. This is essentially a measure of incompleteness.
\end{enumerate}


\section{Discussion}

What did we learn,

\bibliographystyle{plainnat}
\bibliography{bioc}

\end{document}
